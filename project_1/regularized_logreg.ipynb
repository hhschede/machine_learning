{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The original dimensions of the training data set was 10000 samples and 30 columns. After feature and sample filtering, there are 8976 samples and 23 columns\n",
      "Standardized and randomized samples are found as the variables X_train, y_train, X_test, y_test. Values are split for testing and training sets with the ratio of 0.8\n"
     ]
    }
   ],
   "source": [
    "# Modules\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import datetime\n",
    "\n",
    "# Functions\n",
    "from implementations import *\n",
    "from helpers import *\n",
    "\n",
    "#the autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "(labels_raw, data_raw, ids_raw) = load_csv_data(\"data/train.csv\")\n",
    "labels_raw_portion = labels_raw[:10000]\n",
    "data_raw_portion = data_raw[:10000,:]\n",
    "ids_raw_portion = ids_raw[:10000]\n",
    "data_, labels, ids, idx_colrem = process_data(data_raw_portion, labels_raw_portion, ids_raw_portion)\n",
    "data, means, variance = standardize(data_)\n",
    "X_train, y_train, X_test, y_test = split_data(data, labels)\n",
    "\n",
    "print('Standardized and randomized samples are found as the variables X_train, y_train, X_test, y_test. Values' +\n",
    "      ' are split for testing and training sets with the ratio of 0.8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets do some regularized Logistic Regression!\n",
    "\n",
    "def reg_logreg(y, tx, initial_w, lamb, max_iters = 10000, gamma = 0.01, methods = \"sgd\", batch_size = 250, writing = False):\n",
    "    \n",
    "    ws = np.zeros([max_iters + 1, tx.shape[1]])\n",
    "    ws[0] = initial_w \n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    \n",
    "    if methods == \"gd\":\n",
    "        for i in range(max_iters):\n",
    "            h = sigmoid(np.dot(tx, w))\n",
    "            grad = np.dot(tx.T, (h - y)) / y.shape[0] + lamb * np.linalg.norm(w) / y.shape[0]\n",
    "            w -= gamma * grad\n",
    "            ws[i+1] = w\n",
    "            losses.append(compute_loss(y, tx, w, lam = lamb, method = 'reg_logistic'))\n",
    "\n",
    "            if writing:\n",
    "                if i % 500 == 0:\n",
    "                    print(\"iteration: {iter} | loss : {l}\".format(\n",
    "                        iter = i, l=losses[-1] ))\n",
    "\n",
    "                    \n",
    "\n",
    "    if methods == \"sgd\":\n",
    "        for i in range(max_iters):   \n",
    "            for mini_y, mini_X in batch_iter(y, tx, batch_size):                \n",
    "                h = sigmoid(np.dot(mini_X, w))\n",
    "                grad = np.dot(mini_X.T, (h - mini_y)) / mini_y.shape[0] + lam * np.linalg.norm(w) / y.shape[0]\n",
    "                w -= gamma * grad\n",
    "                ws[i+1] = w\n",
    "                losses.append(compute_loss(mini_y, mini_X, w, lam, method = 'reg_logistic'))\n",
    "\n",
    "            if writing:\n",
    "                if i % 500 == 0:\n",
    "                    print(\"iteration: {iter} | loss : {l}\".format(\n",
    "                        iter = i, l=losses[-1] ))\n",
    "\n",
    "    return losses, ws\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/halimaschede/Documents/GitHub/machine_learning/project_1/implementations.py:21: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = np.mean((-y * np.log(sigmoid(tx.dot(w))) -\n",
      "/Users/halimaschede/Documents/GitHub/machine_learning/project_1/implementations.py:21: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = np.mean((-y * np.log(sigmoid(tx.dot(w))) -\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13385925443405555 0.026126163393565972\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.array(p))\n",
    "plt.style.use('seaborn')\n",
    "plt.plot(p)\n",
    "plt.plot(percent_test, c='orange')\n",
    "plt.title('Classification Accuracy Over Iterations')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Percent Accuracy')\n",
    "plt.legend(['Training Accuracy', 'Test Accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
