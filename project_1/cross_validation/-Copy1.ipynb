{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# Functions\n",
    "from implementations_cross_validation import *\n",
    "from helpers import *\n",
    "from preprocessing import *\n",
    "\n",
    "# Autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original dimensions of the training data set was 250000 samples and 30 columns\n",
      " After feature and sample filtering, there are 250000 samples and 30 columns\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "(labels_raw, data_raw, ids_raw) = load_csv_data(\"data/train.csv\")\n",
    "(t_labels, t_data_raw, t_ids) = load_csv_data(\"data/test.csv\")\n",
    "\n",
    "data_, data_t_, labels = process_data(data_raw, t_data_raw, labels_raw,\n",
    "                                      ids_raw, sample_filtering = False, feature_filtering = False,\n",
    "                                      replace = 'median', remove_outlier=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test split\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_data(data_, labels, ratio=0.8, seed=0)\n",
    "\n",
    "# Add interaction terms and polynomial of degree 2 to cross val set (no bias term is added here\n",
    "# since its done inside crossval function)\n",
    "\n",
    "X_train_int = build_interact_terms(X_train)\n",
    "X_test_int = build_interact_terms(X_test)\n",
    "X_train_poly = build_poly(X_train, 2)\n",
    "X_test_poly = build_poly(X_test, 2)\n",
    "X_train = np.c_[X_train_poly, X_train_int]\n",
    "X_test_forstd = np.c_[X_test_poly, X_test_int]\n",
    "\n",
    "# Create standardizations for the split\n",
    "X_train_std, mean, variance = standardize(X_train)\n",
    "X_test_std = standardize_test(X_test_forstd, mean, variance)\n",
    "\n",
    "\n",
    "# Perform PCA\n",
    "eigVal, eigVec, sumEigVal = PCA(X_train_std, threshold = 0.9)\n",
    "X_train_std = X_train_std.dot(eigVec)\n",
    "X_test_std = X_test_std.dot(eigVec)\n",
    "\n",
    "# Add the bias term for the final models\n",
    "y_train, X_train_std = build_model_data(X_train_std, y_train)\n",
    "y_test, X_test_std = build_model_data(X_test_std, y_test)\n",
    "\n",
    "\n",
    "# Initialize boxplots values\n",
    "boxplots = []\n",
    "test_accuracies = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression: Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize w vector\n",
    "initial_w = np.random.rand(X_train_std.shape[1])\n",
    "k_ = 6\n",
    "\n",
    "# Perform linear regression by gradient descent with cross validation (k=4)\n",
    "test_loss_mean, test_loss_var, vector_test_loss, train_loss_mean, w_final, accuracies = least_squares_GD(y_train, X_train, initial_w, gamma = 0.005, k=k_, max_iters = 500)\n",
    "boxplots.append(accuracies)\n",
    "\n",
    "# Perform linear regression by gradient descent on whole training set\n",
    "w = least_squares_GD(y_train, X_train_std, initial_w, gamma = 0.005, k=0, max_iters = 500)\n",
    "\n",
    "# Use w to predict unseen test set labels\n",
    "test_pred_lab = predict_labels(w, X_test_std)\n",
    "test_accuracy = pred_accuracy(test_pred_lab, y_test)\n",
    "test_accuracies.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write results to file\n",
    "\n",
    "file_object = open('cv_results', 'w')\n",
    "file_object.write('fold1, fold2, fold3, fold4, test_set \\n')\n",
    "acc_s = str(accuracies[0]) + ', ' + str(accuracies[1]) + ', ' + str(accuracies[2]) + ', ' + str(accuracies[3])\n",
    "acc_t = str(test_accuracy) + '\\n'\n",
    "file_object.write(acc_s + ', ' + acc_t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression: Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize w vector\n",
    "initial_w = np.random.rand(X_train_std.shape[1])\n",
    "k_ = 6\n",
    "\n",
    "# Perform algorithm with cross validation (k=4)\n",
    "w_final, accuracies = least_squares_SGD(y_train, X_train, initial_w, batch_size=400, gamma = 0.005, k=k_, max_iters=500)\n",
    "boxplots.append(accuracies)\n",
    "\n",
    "# Perform algorithm on whole training set\n",
    "w = least_squares_SGD(y_train, X_train_std, initial_w, gamma = 0.005, batch_size = 1000, k=0, max_iters=500)\n",
    "\n",
    "# Use w to predict unseen test set labels\n",
    "test_pred_lab = predict_labels(w, X_test_std)\n",
    "test_accuracy = pred_accuracy(test_pred_lab, y_test)\n",
    "test_accuracies.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write results to file\n",
    "\n",
    "acc_s = str(accuracies[0]) + ', ' + str(accuracies[1]) + ', ' + str(accuracies[2]) + ', ' + str(accuracies[3])\n",
    "acc_t = str(test_accuracy) + '\\n'\n",
    "file_object.write(acc_s + ', ' + acc_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression: Direct Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_ = 6\n",
    "\n",
    "# Perform linear regression by direct least squares with cross validation (k=4)\n",
    "test_loss_mean, test_loss_var, train_loss_mean, w_final, accuracies = least_squares(y_train, X_train, k_)\n",
    "boxplots.append(accuracies)\n",
    "\n",
    "# Perform linear regression by direct least squares on whole training set\n",
    "w = least_squares(y_train, X_train_std, k=0)\n",
    "\n",
    "# Use w to predict unseen test set labels\n",
    "test_pred_lab = predict_labels(w, X_test_std)\n",
    "test_accuracy = pred_accuracy(test_pred_lab, y_test)\n",
    "test_accuracies.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write results to file\n",
    "\n",
    "acc_s = str(accuracies[0]) + ', ' + str(accuracies[1]) + ', ' + str(accuracies[2]) + ', ' + str(accuracies[3])\n",
    "acc_t = str(test_accuracy) + '\\n'\n",
    "file_object.write(acc_s + ', ' + acc_t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression: Regularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for optimal lambda value to implement for cross validation\n",
    "\n",
    "lambdas = np.logspace(-7, 0, 30)\n",
    "rmse_tr = []\n",
    "rmse_ts = []\n",
    "pred_tr = []\n",
    "pred_ts = []\n",
    "\n",
    "for ind, lambda_ in enumerate(lambdas):\n",
    "    \n",
    "    w = ridge_regression(y_train, X_train_std, lambda_, k=0)\n",
    "    \n",
    "#     rmse_tr.append(np.sqrt(2 * compute_loss(y_train, X_train, w)))\n",
    "    pred_tr.append(pred_accuracy(predict_labels(w, X_train_std), y_train))\n",
    "#     rmse_ts.append(np.sqrt(2 * compute_loss(y_test, X_test, w)))\n",
    "    pred_ts.append(pred_accuracy(predict_labels(w, X_test_std), y_test))\n",
    "    \n",
    "selected_lambda = lambdas[np.argmax(pred_ts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06210169418915616\n"
     ]
    }
   ],
   "source": [
    "print(selected_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_ = 6\n",
    "\n",
    "# Perform regularized linear regression with cross validation (k=4)\n",
    "# Note that the value for lambda that is selected for this cross validation assessment it taken \n",
    "# from the above grid search which provided the best accuracies scores for the test set.\n",
    "\n",
    "w_final, accuracies = ridge_regression(y_train, X_train, lambda_=selected_lambda, k=k_)\n",
    "boxplots.append(accuracies)\n",
    "\n",
    "# Perform regularized linear regression on whole training set\n",
    "w = ridge_regression(y_train, X_train_std, lambda_=selected_lambda, k=0)\n",
    "\n",
    "# Use w to predict unseen test set labels\n",
    "test_pred_lab = predict_labels(w, X_test_std)\n",
    "test_accuracy = pred_accuracy(test_pred_lab, y_test)\n",
    "test_accuracies.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write results to file\n",
    "\n",
    "acc_s = str(accuracies[0]) + ', ' + str(accuracies[1]) + ', ' + str(accuracies[2]) + ', ' + str(accuracies[3])\n",
    "acc_t = str(test_accuracy) + '\\n'\n",
    "file_object.write(acc_s + ', ' + acc_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "initial_w = np.random.rand(X_train_std.shape[1])\n",
    "k_ = 6\n",
    "thresh = 0.5\n",
    "\n",
    "# Perform logistic regression with Newton's Method\n",
    "\n",
    "gen = cross_val(y_train, X_train, k_) # initiate generator object\n",
    "accuracies = []\n",
    "for i in np.arange(k_):\n",
    "    y_tr, x_tr, y_te, x_te = next(gen) # take next subtraining and subtest sets\n",
    "    w = np.random.rand(x_tr.shape[1])\n",
    "    losses, losses_t, acc, acc_t, w = logistic_hessian(y_tr, x_tr, y_te, x_te, w, 0.07, 500, 150, writing=False)\n",
    "    accuracies.append(acc_t[-1])\n",
    "boxplots.append(accuracies)\n",
    "\n",
    "# Perform algorithm on entire training set to retrieve w\n",
    "losses, losses_t, acc, test_accuracy, w = logistic_hessian(y_train, X_train_std, y_test,\n",
    "                                                           X_test_std, initial_w, 0.07, 500, 150, writing=False)\n",
    "test_accuracies.append(test_accuracy[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write results to file\n",
    "\n",
    "acc_s = str(accuracies[0]) + ', ' + str(accuracies[1]) + ', ' + str(accuracies[2]) + ', ' + str(accuracies[3])\n",
    "acc_t = str(test_accuracy) + '\\n'\n",
    "file_object.write(acc_s + ', ' + acc_t)\n",
    "file_object.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[0.72846, 0.74176, 0.7643, 0.76516, 0.76852]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create boxplots\n",
    "print(len(boxplots))\n",
    "plt.style.use('seaborn')\n",
    "plt.boxplot(boxplots, labels=['LinReg GD', 'LinReg SGD','LinReg Direct','LinReg Ridge','LogisticReg'])\n",
    "# plt.boxplot(boxplots, labels=[''])\n",
    "plt.plot(1, test_accuracies[0], marker='o', c='red')\n",
    "plt.plot(2, test_accuracies[1], marker='o', c='red')\n",
    "plt.plot(3, test_accuracies[2], marker='o', c='red')\n",
    "plt.plot(4, test_accuracies[3], marker='o', c='red')\n",
    "plt.plot(5, test_accuracies[4], marker='o', c='red')\n",
    "print(test_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with Varying Degrees and Interaction Terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Without addition of features by degree 2 or interaction terms or**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test split\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_data(data_, labels, ratio=0.8, seed=0)\n",
    "\n",
    "# Create standardizations for the split\n",
    "X_train_std, mean, variance = standardize(X_train)\n",
    "X_test_std = standardize_test(X_test, mean, variance)\n",
    "\n",
    "\n",
    "# Perform PCA\n",
    "eigVal, eigVec, sumEigVal = PCA(X_train_std, threshold = 0.9)\n",
    "X_train_std = X_train_std.dot(eigVec)\n",
    "X_test_std = X_test_std.dot(eigVec)\n",
    "\n",
    "# Add the bias term for the final models\n",
    "y_train, X_train_std = build_model_data(X_train_std, y_train)\n",
    "y_test, X_test_std = build_model_data(X_test_std, y_test)\n",
    "\n",
    "\n",
    "# Initialize boxplots values\n",
    "boxplots_log = []\n",
    "test_accuracies_log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "initial_w = np.random.rand(X_train_std.shape[1])\n",
    "k_ = 6\n",
    "thresh = 0.5\n",
    "\n",
    "# Perform logistic regression with Newton's Method\n",
    "\n",
    "gen = cross_val(y_train, X_train, k_) # initiate generator object\n",
    "accuracies = []\n",
    "for i in np.arange(k_):\n",
    "    y_tr, x_tr, y_te, x_te = next(gen) # take next subtraining and subtest sets\n",
    "    w = np.random.rand(x_tr.shape[1])\n",
    "    losses, losses_t, acc, acc_t, w = logistic_hessian(y_tr, x_tr, y_te, x_te, w, 0.07, 500, 150, writing=False)\n",
    "    accuracies.append(acc_t[-1])\n",
    "boxplots_log.append(accuracies)\n",
    "\n",
    "# Perform algorithm on entire training set to retrieve w\n",
    "losses, losses_t, acc, test_accuracy, w = logistic_hessian(y_train, X_train_std, y_test,\n",
    "                                                           X_test_std, initial_w, 0.07, 500, 150, writing=False)\n",
    "test_accuracies_log.append(test_accuracy[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With degree 2 without interaction terms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test split\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_data(data_, labels, ratio=0.8, seed=0)\n",
    "\n",
    "X_train = build_poly(X_train, 2)\n",
    "X_test = build_poly(X_test, 2)\n",
    "\n",
    "# Create standardizations for the split\n",
    "X_train_std, mean, variance = standardize(X_train)\n",
    "X_test_std = standardize_test(X_test, mean, variance)\n",
    "\n",
    "# Perform PCA\n",
    "eigVal, eigVec, sumEigVal = PCA(X_train_std, threshold = 0.9)\n",
    "X_train_std = X_train_std.dot(eigVec)\n",
    "X_test_std = X_test_std.dot(eigVec)\n",
    "\n",
    "# Add the bias term for the final models\n",
    "y_train, X_train_std = build_model_data(X_train_std, y_train)\n",
    "y_test, X_test_std = build_model_data(X_test_std, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "initial_w = np.random.rand(X_train_std.shape[1])\n",
    "k_ = 6\n",
    "thresh = 0.5\n",
    "\n",
    "# Perform logistic regression with Newton's Method\n",
    "\n",
    "gen = cross_val(y_train, X_train, k_) # initiate generator object\n",
    "accuracies = []\n",
    "for i in np.arange(k_):\n",
    "    y_tr, x_tr, y_te, x_te = next(gen) # take next subtraining and subtest sets\n",
    "    w = np.random.rand(x_tr.shape[1])\n",
    "    losses, losses_t, acc, acc_t, w = logistic_hessian(y_tr, x_tr, y_te, x_te, w, 0.07, 500, 150, writing=False)\n",
    "    accuracies.append(acc_t[-1])\n",
    "boxplots_log.append(accuracies)\n",
    "\n",
    "# Perform algorithm on entire training set to retrieve w\n",
    "losses, losses_t, acc, test_accuracy, w = logistic_hessian(y_train, X_train_std, y_test,\n",
    "                                                           X_test_std, initial_w, 0.07, 500, 150, writing=False)\n",
    "test_accuracies_log.append(test_accuracy[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With degree 3 without interaction terms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test split\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_data(data_, labels, ratio=0.8, seed=0)\n",
    "\n",
    "X_train = build_poly(X_train, 3)\n",
    "X_test = build_poly(X_test, 3)\n",
    "\n",
    "# Create standardizations for the split\n",
    "X_train_std, mean, variance = standardize(X_train)\n",
    "X_test_std = standardize_test(X_test, mean, variance)\n",
    "\n",
    "# Perform PCA\n",
    "eigVal, eigVec, sumEigVal = PCA(X_train_std, threshold = 0.9)\n",
    "X_train_std = X_train_std.dot(eigVec)\n",
    "X_test_std = X_test_std.dot(eigVec)\n",
    "\n",
    "# Add the bias term for the final models\n",
    "y_train, X_train_std = build_model_data(X_train_std, y_train)\n",
    "y_test, X_test_std = build_model_data(X_test_std, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "initial_w = np.random.rand(X_train_std.shape[1])\n",
    "k_ = 6\n",
    "thresh = 0.5\n",
    "\n",
    "# Perform logistic regression with Newton's Method\n",
    "\n",
    "gen = cross_val(y_train, X_train, k_) # initiate generator object\n",
    "accuracies = []\n",
    "for i in np.arange(k_):\n",
    "    y_tr, x_tr, y_te, x_te = next(gen) # take next subtraining and subtest sets\n",
    "    w = np.random.rand(x_tr.shape[1])\n",
    "    losses, losses_t, acc, acc_t, w = logistic_hessian(y_tr, x_tr, y_te, x_te, w, 0.07, 500, 150, writing=False)\n",
    "    accuracies.append(acc_t[-1])\n",
    "boxplots_log.append(accuracies)\n",
    "\n",
    "# Perform algorithm on entire training set to retrieve w\n",
    "losses, losses_t, acc, test_accuracy, w = logistic_hessian(y_train, X_train_std, y_test,\n",
    "                                                           X_test_std, initial_w, 0.07, 500, 150, writing=False)\n",
    "test_accuracies_log.append(test_accuracy[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With degree 2 and interaction terms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test split\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_data(data_, labels, ratio=0.8, seed=0)\n",
    "\n",
    "# Add interaction terms and polynomial of degree 2 to cross val set (no bias term is added here\n",
    "# since its done inside crossval function)\n",
    "\n",
    "X_train_int = build_interact_terms(X_train)\n",
    "X_test_int = build_interact_terms(X_test)\n",
    "X_train_poly = build_poly(X_train, 2)\n",
    "X_test_poly = build_poly(X_test, 2)\n",
    "X_train = np.c_[X_train_poly, X_train_int]\n",
    "X_test_forstd = np.c_[X_test_poly, X_test_int]\n",
    "\n",
    "# Create standardizations for the split\n",
    "X_train_std, mean, variance = standardize(X_train)\n",
    "X_test_std = standardize_test(X_test_forstd, mean, variance)\n",
    "\n",
    "\n",
    "# Perform PCA\n",
    "eigVal, eigVec, sumEigVal = PCA(X_train_std, threshold = 0.9)\n",
    "X_train_std = X_train_std.dot(eigVec)\n",
    "X_test_std = X_test_std.dot(eigVec)\n",
    "\n",
    "# Add the bias term for the final models\n",
    "y_train, X_train_std = build_model_data(X_train_std, y_train)\n",
    "y_test, X_test_std = build_model_data(X_test_std, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "initial_w = np.random.rand(X_train_std.shape[1])\n",
    "k_ = 6\n",
    "thresh = 0.5\n",
    "\n",
    "# Perform logistic regression with Newton's Method\n",
    "\n",
    "gen = cross_val(y_train, X_train, k_) # initiate generator object\n",
    "accuracies = []\n",
    "for i in np.arange(k_):\n",
    "    y_tr, x_tr, y_te, x_te = next(gen) # take next subtraining and subtest sets\n",
    "    w = np.random.rand(x_tr.shape[1])\n",
    "    losses, losses_t, acc, acc_t, w = logistic_hessian(y_tr, x_tr, y_te, x_te, w, 0.07, 500, 150, writing=False)\n",
    "    accuracies.append(acc_t[-1])\n",
    "boxplots_log.append(accuracies)\n",
    "\n",
    "# Perform algorithm on entire training set to retrieve w\n",
    "losses, losses_t, acc, test_accuracy, w = logistic_hessian(y_train, X_train_std, y_test,\n",
    "                                                           X_test_std, initial_w, 0.07, 500, 150, writing=False)\n",
    "test_accuracies_log.append(test_accuracy[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With degree 3 and interaction terms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test split\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_data(data_, labels, ratio=0.8, seed=0)\n",
    "\n",
    "# Add interaction terms and polynomial of degree 2 to cross val set (no bias term is added here\n",
    "# since its done inside crossval function)\n",
    "\n",
    "X_train_int = build_interact_terms(X_train)\n",
    "X_test_int = build_interact_terms(X_test)\n",
    "X_train_poly = build_poly(X_train, 3)\n",
    "X_test_poly = build_poly(X_test, 3)\n",
    "X_train = np.c_[X_train_poly, X_train_int]\n",
    "X_test_forstd = np.c_[X_test_poly, X_test_int]\n",
    "\n",
    "# Create standardizations for the split\n",
    "X_train_std, mean, variance = standardize(X_train)\n",
    "X_test_std = standardize_test(X_test_forstd, mean, variance)\n",
    "\n",
    "\n",
    "# Perform PCA\n",
    "eigVal, eigVec, sumEigVal = PCA(X_train_std, threshold = 0.9)\n",
    "X_train_std = X_train_std.dot(eigVec)\n",
    "X_test_std = X_test_std.dot(eigVec)\n",
    "\n",
    "# Add the bias term for the final models\n",
    "y_train, X_train_std = build_model_data(X_train_std, y_train)\n",
    "y_test, X_test_std = build_model_data(X_test_std, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "initial_w = np.random.rand(X_train_std.shape[1])\n",
    "k_ = 6\n",
    "thresh = 0.5\n",
    "\n",
    "# Perform logistic regression with Newton's Method\n",
    "\n",
    "gen = cross_val(y_train, X_train, k_) # initiate generator object\n",
    "accuracies = []\n",
    "for i in np.arange(k_):\n",
    "    y_tr, x_tr, y_te, x_te = next(gen) # take next subtraining and subtest sets\n",
    "    w = np.random.rand(x_tr.shape[1])\n",
    "    losses, losses_t, acc, acc_t, w = logistic_hessian(y_tr, x_tr, y_te, x_te, w, 0.07, 500, 150, writing=False)\n",
    "    accuracies.append(acc_t[-1])\n",
    "boxplots_log.append(accuracies)\n",
    "\n",
    "# Perform algorithm on entire training set to retrieve w\n",
    "losses, losses_t, acc, test_accuracy, w = logistic_hessian(y_train, X_train_std, y_test,\n",
    "                                                           X_test_std, initial_w, 0.07, 500, 150, writing=False)\n",
    "test_accuracies_log.append(test_accuracy[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[0.73474, 0.7533, 0.7481, 0.76852, 0.77008]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create boxplots\n",
    "print(len(boxplots_log))\n",
    "plt.style.use('seaborn')\n",
    "plt.boxplot(boxplots_log, labels=['-D/-IT', '2D/-IT','3D/-IT','2D/+IT','3D/+IT'])\n",
    "# plt.boxplot(boxplots, labels=[''])\n",
    "plt.plot(1, test_accuracies_log[0], marker='o', c='red')\n",
    "plt.plot(2, test_accuracies_log[1], marker='o', c='red')\n",
    "plt.plot(3, test_accuracies_log[2], marker='o', c='red')\n",
    "plt.plot(4, test_accuracies_log[3], marker='o', c='red')\n",
    "plt.plot(5, test_accuracies_log[4], marker='o', c='red')\n",
    "print(test_accuracies_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada]",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
