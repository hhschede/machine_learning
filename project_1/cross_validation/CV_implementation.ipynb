{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# Functions\n",
    "from implementations_cross_validation import *\n",
    "from helpers import *\n",
    "from preprocessing import *\n",
    "\n",
    "# Autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original dimensions of the training data set was 250000 samples and 30 columns\n",
      " After feature and sample filtering, there are 250000 samples and 30 columns\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "(labels_raw, data_raw, ids_raw) = load_csv_data(\"data/train.csv\")\n",
    "(t_labels, t_data_raw, t_ids) = load_csv_data(\"data/test.csv\")\n",
    "\n",
    "data_, data_t_, labels = process_data(data_raw, t_data_raw, labels_raw,\n",
    "                                      ids_raw, sample_filtering = False, feature_filtering = False,\n",
    "                                      replace = 'median', remove_outlier=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test split\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_data(data_, labels, ratio=0.8, seed=0)\n",
    "\n",
    "# Add interaction terms and polynomial of degree 2 to cross val set (no bias term is added here\n",
    "# since its done inside crossval function)\n",
    "\n",
    "X_train_int = build_interact_terms(X_train)\n",
    "X_test_int = build_interact_terms(X_test)\n",
    "X_train_poly = build_poly(X_train, 2)\n",
    "X_test_poly = build_poly(X_test, 2)\n",
    "X_train = np.c_[X_train_poly, X_train_int]\n",
    "X_test_forstd = np.c_[X_test_poly, X_test_int]\n",
    "\n",
    "# Create standardizations for the split\n",
    "X_train_std, mean, variance = standardize(X_train)\n",
    "X_test_std = standardize_test(X_test_forstd, mean, variance)\n",
    "\n",
    "\n",
    "# Perform PCA\n",
    "eigVal, eigVec, sumEigVal = PCA(X_train_std, threshold = 0.9)\n",
    "X_train_std = X_train_std.dot(eigVec)\n",
    "X_test_std = X_test_std.dot(eigVec)\n",
    "\n",
    "# Add the bias term for the final models\n",
    "y_train, X_train_std = build_model_data(X_train_std, y_train)\n",
    "y_test, X_test_std = build_model_data(X_test_std, y_test)\n",
    "\n",
    "\n",
    "# Initialize boxplots values\n",
    "boxplots = []\n",
    "test_accuracies = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression: Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize w vector\n",
    "initial_w = np.random.rand(X_train_std.shape[1])\n",
    "k_ = 6\n",
    "\n",
    "# Perform linear regression by gradient descent with cross validation (k=4)\n",
    "test_loss_mean, test_loss_var, vector_test_loss, train_loss_mean, w_final, accuracies = least_squares_GD(y_train, X_train, initial_w, gamma = 0.005, k=k_, max_iters = 500)\n",
    "boxplots.append(accuracies)\n",
    "\n",
    "# Perform linear regression by gradient descent on whole training set\n",
    "w = least_squares_GD(y_train, X_train_std, initial_w, gamma = 0.005, k=0, max_iters = 500)\n",
    "\n",
    "# Use w to predict unseen test set labels\n",
    "test_pred_lab = predict_labels(w, X_test_std)\n",
    "test_accuracy = pred_accuracy(test_pred_lab, y_test)\n",
    "test_accuracies.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write results to file\n",
    "\n",
    "file_object = open('cv_results', 'w')\n",
    "file_object.write('fold1, fold2, fold3, fold4, test_set \\n')\n",
    "acc_s = str(accuracies[0]) + ', ' + str(accuracies[1]) + ', ' + str(accuracies[2]) + ', ' + str(accuracies[3])\n",
    "acc_t = str(test_accuracy) + '\\n'\n",
    "file_object.write(acc_s + ', ' + acc_t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression: Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize w vector\n",
    "initial_w = np.random.rand(X_train_std.shape[1])\n",
    "k_ = 6\n",
    "\n",
    "# Perform algorithm with cross validation (k=4)\n",
    "w_final, accuracies = least_squares_SGD(y_train, X_train, initial_w, batch_size=400, gamma = 0.005, k=k_, max_iters=500)\n",
    "boxplots.append(accuracies)\n",
    "\n",
    "# Perform algorithm on whole training set\n",
    "w = least_squares_SGD(y_train, X_train_std, initial_w, gamma = 0.005, batch_size = 1000, k=0, max_iters=500)\n",
    "\n",
    "# Use w to predict unseen test set labels\n",
    "test_pred_lab = predict_labels(w, X_test_std)\n",
    "test_accuracy = pred_accuracy(test_pred_lab, y_test)\n",
    "test_accuracies.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write results to file\n",
    "\n",
    "acc_s = str(accuracies[0]) + ', ' + str(accuracies[1]) + ', ' + str(accuracies[2]) + ', ' + str(accuracies[3])\n",
    "acc_t = str(test_accuracy) + '\\n'\n",
    "file_object.write(acc_s + ', ' + acc_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression: Direct Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_ = 6\n",
    "\n",
    "# Perform linear regression by direct least squares with cross validation (k=4)\n",
    "test_loss_mean, test_loss_var, train_loss_mean, w_final, accuracies = least_squares(y_train, X_train, k_)\n",
    "boxplots.append(accuracies)\n",
    "\n",
    "# Perform linear regression by direct least squares on whole training set\n",
    "w = least_squares(y_train, X_train_std, k=0)\n",
    "\n",
    "# Use w to predict unseen test set labels\n",
    "test_pred_lab = predict_labels(w, X_test_std)\n",
    "test_accuracy = pred_accuracy(test_pred_lab, y_test)\n",
    "test_accuracies.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write results to file\n",
    "\n",
    "acc_s = str(accuracies[0]) + ', ' + str(accuracies[1]) + ', ' + str(accuracies[2]) + ', ' + str(accuracies[3])\n",
    "acc_t = str(test_accuracy) + '\\n'\n",
    "file_object.write(acc_s + ', ' + acc_t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression: Regularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for optimal lambda value to implement for cross validation\n",
    "\n",
    "lambdas = np.logspace(-7, 0, 30)\n",
    "rmse_tr = []\n",
    "rmse_ts = []\n",
    "pred_tr = []\n",
    "pred_ts = []\n",
    "\n",
    "for ind, lambda_ in enumerate(lambdas):\n",
    "    \n",
    "    w = ridge_regression(y_train, X_train_std, lambda_, k=0)\n",
    "    \n",
    "#     rmse_tr.append(np.sqrt(2 * compute_loss(y_train, X_train, w)))\n",
    "    pred_tr.append(pred_accuracy(predict_labels(w, X_train_std), y_train))\n",
    "#     rmse_ts.append(np.sqrt(2 * compute_loss(y_test, X_test, w)))\n",
    "    pred_ts.append(pred_accuracy(predict_labels(w, X_test_std), y_test))\n",
    "    \n",
    "selected_lambda = lambdas[np.argmax(pred_ts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06210169418915616\n"
     ]
    }
   ],
   "source": [
    "print(selected_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_ = 6\n",
    "\n",
    "# Perform regularized linear regression with cross validation (k=4)\n",
    "# Note that the value for lambda that is selected for this cross validation assessment it taken \n",
    "# from the above grid search which provided the best accuracies scores for the test set.\n",
    "\n",
    "w_final, accuracies = ridge_regression(y_train, X_train, lambda_=selected_lambda, k=k_)\n",
    "boxplots.append(accuracies)\n",
    "\n",
    "# Perform regularized linear regression on whole training set\n",
    "w = ridge_regression(y_train, X_train_std, lambda_=selected_lambda, k=0)\n",
    "\n",
    "# Use w to predict unseen test set labels\n",
    "test_pred_lab = predict_labels(w, X_test_std)\n",
    "test_accuracy = pred_accuracy(test_pred_lab, y_test)\n",
    "test_accuracies.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write results to file\n",
    "\n",
    "acc_s = str(accuracies[0]) + ', ' + str(accuracies[1]) + ', ' + str(accuracies[2]) + ', ' + str(accuracies[3])\n",
    "acc_t = str(test_accuracy) + '\\n'\n",
    "file_object.write(acc_s + ', ' + acc_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "initial_w = np.random.rand(X_train_std.shape[1])\n",
    "k_ = 6\n",
    "thresh = 0.5\n",
    "\n",
    "# Perform logistic regression with Newton's Method\n",
    "\n",
    "gen = cross_val(y_train, X_train, k_) # initiate generator object\n",
    "accuracies = []\n",
    "for i in np.arange(k_):\n",
    "    y_tr, x_tr, y_te, x_te = next(gen) # take next subtraining and subtest sets\n",
    "    w = np.random.rand(x_tr.shape[1])\n",
    "    losses, losses_t, acc, acc_t, w = logistic_hessian(y_tr, x_tr, y_te, x_te, w, 0.07, 500, 150, writing=False)\n",
    "    accuracies.append(acc_t[-1])\n",
    "boxplots.append(accuracies)\n",
    "\n",
    "# Perform algorithm on entire training set to retrieve w\n",
    "losses, losses_t, acc, test_accuracy, w = logistic_hessian(y_train, X_train_std, y_test,\n",
    "                                                           X_test_std, initial_w, 0.07, 500, 150, writing=False)\n",
    "test_accuracies.append(test_accuracy[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write results to file\n",
    "\n",
    "acc_s = str(accuracies[0]) + ', ' + str(accuracies[1]) + ', ' + str(accuracies[2]) + ', ' + str(accuracies[3])\n",
    "acc_t = str(test_accuracy) + '\\n'\n",
    "file_object.write(acc_s + ', ' + acc_t)\n",
    "file_object.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create boxplots\n",
    "plt.style.use('seaborn')\n",
    "plt.boxplot(boxplots, labels=['LinReg GD', 'LinReg SGD','LinReg Direct','LinReg Ridge','LogisticReg'])\n",
    "plt.xlabel('Learning Algorithm', weight='bold', fontsize=15)\n",
    "plt.ylabel('Prediction Accuracy', weight='bold', fontsize=15)\n",
    "plt.plot(1, test_accuracies[0], marker='o', c='red')\n",
    "plt.plot(2, test_accuracies[1], marker='o', c='red')\n",
    "plt.plot(3, test_accuracies[2], marker='o', c='red')\n",
    "plt.plot(4, test_accuracies[3], marker='o', c='red')\n",
    "plt.plot(5, test_accuracies[4], marker='o', c='red')\n",
    "plt.savefig('LearningAlgs.png')\n",
    "# print(test_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with Varying Degrees and Interaction Terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Without addition of features by degree 2 or interaction terms or**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test split\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_data(data_, labels, ratio=0.8, seed=0)\n",
    "\n",
    "# Create standardizations for the split\n",
    "X_train_std, mean, variance = standardize(X_train)\n",
    "X_test_std = standardize_test(X_test, mean, variance)\n",
    "\n",
    "\n",
    "# Perform PCA\n",
    "eigVal, eigVec, sumEigVal = PCA(X_train_std, threshold = 0.9)\n",
    "X_train_std = X_train_std.dot(eigVec)\n",
    "X_test_std = X_test_std.dot(eigVec)\n",
    "\n",
    "# Add the bias term for the final models\n",
    "y_train, X_train_std = build_model_data(X_train_std, y_train)\n",
    "y_test, X_test_std = build_model_data(X_test_std, y_test)\n",
    "\n",
    "\n",
    "# Initialize boxplots values\n",
    "boxplots_log = []\n",
    "test_accuracies_log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "initial_w = np.random.rand(X_train_std.shape[1])\n",
    "k_ = 6\n",
    "thresh = 0.5\n",
    "\n",
    "# Perform logistic regression with Newton's Method\n",
    "\n",
    "gen = cross_val(y_train, X_train, k_) # initiate generator object\n",
    "accuracies = []\n",
    "for i in np.arange(k_):\n",
    "    y_tr, x_tr, y_te, x_te = next(gen) # take next subtraining and subtest sets\n",
    "    w = np.random.rand(x_tr.shape[1])\n",
    "    losses, losses_t, acc, acc_t, w = logistic_hessian(y_tr, x_tr, y_te, x_te, w, 0.07, 500, 150, writing=False)\n",
    "    accuracies.append(acc_t[-1])\n",
    "boxplots_log.append(accuracies)\n",
    "\n",
    "# Perform algorithm on entire training set to retrieve w\n",
    "losses, losses_t, acc, test_accuracy, w = logistic_hessian(y_train, X_train_std, y_test,\n",
    "                                                           X_test_std, initial_w, 0.07, 500, 150, writing=False)\n",
    "test_accuracies_log.append(test_accuracy[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With degree 2 without interaction terms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test split\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_data(data_, labels, ratio=0.8, seed=0)\n",
    "\n",
    "X_train = build_poly(X_train, 2)\n",
    "X_test = build_poly(X_test, 2)\n",
    "\n",
    "# Create standardizations for the split\n",
    "X_train_std, mean, variance = standardize(X_train)\n",
    "X_test_std = standardize_test(X_test, mean, variance)\n",
    "\n",
    "# Perform PCA\n",
    "eigVal, eigVec, sumEigVal = PCA(X_train_std, threshold = 0.9)\n",
    "X_train_std = X_train_std.dot(eigVec)\n",
    "X_test_std = X_test_std.dot(eigVec)\n",
    "\n",
    "# Add the bias term for the final models\n",
    "y_train, X_train_std = build_model_data(X_train_std, y_train)\n",
    "y_test, X_test_std = build_model_data(X_test_std, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "initial_w = np.random.rand(X_train_std.shape[1])\n",
    "k_ = 6\n",
    "thresh = 0.5\n",
    "\n",
    "# Perform logistic regression with Newton's Method\n",
    "\n",
    "gen = cross_val(y_train, X_train, k_) # initiate generator object\n",
    "accuracies = []\n",
    "for i in np.arange(k_):\n",
    "    y_tr, x_tr, y_te, x_te = next(gen) # take next subtraining and subtest sets\n",
    "    w = np.random.rand(x_tr.shape[1])\n",
    "    losses, losses_t, acc, acc_t, w = logistic_hessian(y_tr, x_tr, y_te, x_te, w, 0.07, 500, 150, writing=False)\n",
    "    accuracies.append(acc_t[-1])\n",
    "boxplots_log.append(accuracies)\n",
    "\n",
    "# Perform algorithm on entire training set to retrieve w\n",
    "losses, losses_t, acc, test_accuracy, w = logistic_hessian(y_train, X_train_std, y_test,\n",
    "                                                           X_test_std, initial_w, 0.07, 500, 150, writing=False)\n",
    "test_accuracies_log.append(test_accuracy[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With degree 3 without interaction terms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test split\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_data(data_, labels, ratio=0.8, seed=0)\n",
    "\n",
    "X_train = build_poly(X_train, 3)\n",
    "X_test = build_poly(X_test, 3)\n",
    "\n",
    "# Create standardizations for the split\n",
    "X_train_std, mean, variance = standardize(X_train)\n",
    "X_test_std = standardize_test(X_test, mean, variance)\n",
    "\n",
    "# Perform PCA\n",
    "eigVal, eigVec, sumEigVal = PCA(X_train_std, threshold = 0.9)\n",
    "X_train_std = X_train_std.dot(eigVec)\n",
    "X_test_std = X_test_std.dot(eigVec)\n",
    "\n",
    "# Add the bias term for the final models\n",
    "y_train, X_train_std = build_model_data(X_train_std, y_train)\n",
    "y_test, X_test_std = build_model_data(X_test_std, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "initial_w = np.random.rand(X_train_std.shape[1])\n",
    "k_ = 6\n",
    "thresh = 0.5\n",
    "\n",
    "# Perform logistic regression with Newton's Method\n",
    "\n",
    "gen = cross_val(y_train, X_train, k_) # initiate generator object\n",
    "accuracies = []\n",
    "for i in np.arange(k_):\n",
    "    y_tr, x_tr, y_te, x_te = next(gen) # take next subtraining and subtest sets\n",
    "    w = np.random.rand(x_tr.shape[1])\n",
    "    losses, losses_t, acc, acc_t, w = logistic_hessian(y_tr, x_tr, y_te, x_te, w, 0.07, 500, 150, writing=False)\n",
    "    accuracies.append(acc_t[-1])\n",
    "boxplots_log.append(accuracies)\n",
    "\n",
    "# Perform algorithm on entire training set to retrieve w\n",
    "losses, losses_t, acc, test_accuracy, w = logistic_hessian(y_train, X_train_std, y_test,\n",
    "                                                           X_test_std, initial_w, 0.07, 500, 150, writing=False)\n",
    "test_accuracies_log.append(test_accuracy[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With degree 2 and interaction terms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test split\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_data(data_, labels, ratio=0.8, seed=0)\n",
    "\n",
    "# Add interaction terms and polynomial of degree 2 to cross val set (no bias term is added here\n",
    "# since its done inside crossval function)\n",
    "\n",
    "X_train_int = build_interact_terms(X_train)\n",
    "X_test_int = build_interact_terms(X_test)\n",
    "X_train_poly = build_poly(X_train, 2)\n",
    "X_test_poly = build_poly(X_test, 2)\n",
    "X_train = np.c_[X_train_poly, X_train_int]\n",
    "X_test_forstd = np.c_[X_test_poly, X_test_int]\n",
    "\n",
    "# Create standardizations for the split\n",
    "X_train_std, mean, variance = standardize(X_train)\n",
    "X_test_std = standardize_test(X_test_forstd, mean, variance)\n",
    "\n",
    "\n",
    "# Perform PCA\n",
    "eigVal, eigVec, sumEigVal = PCA(X_train_std, threshold = 0.9)\n",
    "X_train_std = X_train_std.dot(eigVec)\n",
    "X_test_std = X_test_std.dot(eigVec)\n",
    "\n",
    "# Add the bias term for the final models\n",
    "y_train, X_train_std = build_model_data(X_train_std, y_train)\n",
    "y_test, X_test_std = build_model_data(X_test_std, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "initial_w = np.random.rand(X_train_std.shape[1])\n",
    "k_ = 6\n",
    "thresh = 0.5\n",
    "\n",
    "# Perform logistic regression with Newton's Method\n",
    "\n",
    "gen = cross_val(y_train, X_train, k_) # initiate generator object\n",
    "accuracies = []\n",
    "for i in np.arange(k_):\n",
    "    y_tr, x_tr, y_te, x_te = next(gen) # take next subtraining and subtest sets\n",
    "    w = np.random.rand(x_tr.shape[1])\n",
    "    losses, losses_t, acc, acc_t, w = logistic_hessian(y_tr, x_tr, y_te, x_te, w, 0.07, 500, 150, writing=False)\n",
    "    accuracies.append(acc_t[-1])\n",
    "boxplots_log.append(accuracies)\n",
    "\n",
    "# Perform algorithm on entire training set to retrieve w\n",
    "losses, losses_t, acc, test_accuracy, w = logistic_hessian(y_train, X_train_std, y_test,\n",
    "                                                           X_test_std, initial_w, 0.07, 500, 150, writing=False)\n",
    "test_accuracies_log.append(test_accuracy[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With degree 3 and interaction terms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test split\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_data(data_, labels, ratio=0.8, seed=0)\n",
    "\n",
    "# Add interaction terms and polynomial of degree 2 to cross val set (no bias term is added here\n",
    "# since its done inside crossval function)\n",
    "\n",
    "X_train_int = build_interact_terms(X_train)\n",
    "X_test_int = build_interact_terms(X_test)\n",
    "X_train_poly = build_poly(X_train, 3)\n",
    "X_test_poly = build_poly(X_test, 3)\n",
    "X_train = np.c_[X_train_poly, X_train_int]\n",
    "X_test_forstd = np.c_[X_test_poly, X_test_int]\n",
    "\n",
    "# Create standardizations for the split\n",
    "X_train_std, mean, variance = standardize(X_train)\n",
    "X_test_std = standardize_test(X_test_forstd, mean, variance)\n",
    "\n",
    "\n",
    "# Perform PCA\n",
    "eigVal, eigVec, sumEigVal = PCA(X_train_std, threshold = 0.9)\n",
    "X_train_std = X_train_std.dot(eigVec)\n",
    "X_test_std = X_test_std.dot(eigVec)\n",
    "\n",
    "# Add the bias term for the final models\n",
    "y_train, X_train_std = build_model_data(X_train_std, y_train)\n",
    "y_test, X_test_std = build_model_data(X_test_std, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "initial_w = np.random.rand(X_train_std.shape[1])\n",
    "k_ = 6\n",
    "thresh = 0.5\n",
    "\n",
    "# Perform logistic regression with Newton's Method\n",
    "\n",
    "gen = cross_val(y_train, X_train, k_) # initiate generator object\n",
    "accuracies = []\n",
    "for i in np.arange(k_):\n",
    "    y_tr, x_tr, y_te, x_te = next(gen) # take next subtraining and subtest sets\n",
    "    w = np.random.rand(x_tr.shape[1])\n",
    "    losses, losses_t, acc, acc_t, w = logistic_hessian(y_tr, x_tr, y_te, x_te, w, 0.07, 500, 150, writing=False)\n",
    "    accuracies.append(acc_t[-1])\n",
    "boxplots_log.append(accuracies)\n",
    "\n",
    "# Perform algorithm on entire training set to retrieve w\n",
    "losses, losses_t, acc, test_accuracy, w = logistic_hessian(y_train, X_train_std, y_test,\n",
    "                                                           X_test_std, initial_w, 0.07, 500, 150, writing=False)\n",
    "test_accuracies_log.append(test_accuracy[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create boxplots\n",
    "print(len(boxplots_log))\n",
    "plt.style.use('seaborn')\n",
    "plt.boxplot(boxplots_log, labels=['-D/-IT', '2D/-IT','3D/-IT','2D/+IT','3D/+IT'])\n",
    "# plt.boxplot(boxplots, labels=[''])\n",
    "plt.xlabel('Features Combination Method', weight='bold', fontsize=15)\n",
    "plt.ylabel('Prediction Accuracy', weight='bold', fontsize=15)\n",
    "plt.plot(1, test_accuracies_log[0], marker='o', c='red')\n",
    "plt.plot(2, test_accuracies_log[1], marker='o', c='red')\n",
    "plt.plot(3, test_accuracies_log[2], marker='o', c='red')\n",
    "plt.plot(4, test_accuracies_log[3], marker='o', c='red')\n",
    "plt.plot(5, test_accuracies_log[4], marker='o', c='red')\n",
    "plt.savefig('FeatureExpansion.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Different Preprocessing Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With sample and feature filtering. Replace by Mean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original dimensions of the training data set was 250000 samples and 30 columns\n",
      " After feature and sample filtering, there are 223877 samples and 23 columns\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "(labels_raw, data_raw, ids_raw) = load_csv_data(\"data/train.csv\")\n",
    "(t_labels, t_data_raw, t_ids) = load_csv_data(\"data/test.csv\")\n",
    "\n",
    "data_, data_t_, labels = process_data(data_raw, t_data_raw, labels_raw,\n",
    "                                      ids_raw, sample_filtering = True, feature_filtering = True,\n",
    "                                      replace = 'mean', remove_outlier=False)\n",
    "\n",
    "# Create train/test split\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_data(data_, labels, ratio=0.8, seed=0)\n",
    "\n",
    "# Add interaction terms and polynomial of degree 2 to cross val set (no bias term is added here\n",
    "# since its done inside crossval function)\n",
    "\n",
    "X_train_int = build_interact_terms(X_train)\n",
    "X_test_int = build_interact_terms(X_test)\n",
    "X_train_poly = build_poly(X_train, 3)\n",
    "X_test_poly = build_poly(X_test, 3)\n",
    "X_train = np.c_[X_train_poly, X_train_int]\n",
    "X_test_forstd = np.c_[X_test_poly, X_test_int]\n",
    "\n",
    "# Create standardizations for the split\n",
    "X_train_std, mean, variance = standardize(X_train)\n",
    "X_test_std = standardize_test(X_test_forstd, mean, variance)\n",
    "\n",
    "\n",
    "# Perform PCA\n",
    "eigVal, eigVec, sumEigVal = PCA(X_train_std, threshold = 0.9)\n",
    "X_train_std = X_train_std.dot(eigVec)\n",
    "X_test_std = X_test_std.dot(eigVec)\n",
    "\n",
    "# Add the bias term for the final models\n",
    "y_train, X_train_std = build_model_data(X_train_std, y_train)\n",
    "y_test, X_test_std = build_model_data(X_test_std, y_test)\n",
    "\n",
    "boxplots_preprocessing = []\n",
    "test_accuracies_preprocessing = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "initial_w = np.random.rand(X_train_std.shape[1])\n",
    "k_ = 6\n",
    "thresh = 0.5\n",
    "\n",
    "# Perform logistic regression with Newton's Method\n",
    "\n",
    "gen = cross_val(y_train, X_train, k_) # initiate generator object\n",
    "accuracies = []\n",
    "for i in np.arange(k_):\n",
    "    y_tr, x_tr, y_te, x_te = next(gen) # take next subtraining and subtest sets\n",
    "    w = np.random.rand(x_tr.shape[1])\n",
    "    losses, losses_t, acc, acc_t, w = logistic_hessian(y_tr, x_tr, y_te, x_te, w, 0.07, 500, 150, writing=False)\n",
    "    accuracies.append(acc_t[-1])\n",
    "boxplots_preprocessing.append(accuracies)\n",
    "\n",
    "# Perform algorithm on entire training set to retrieve w\n",
    "losses, losses_t, acc, test_accuracy, w = logistic_hessian(y_train, X_train_std, y_test,\n",
    "                                                           X_test_std, initial_w, 0.07, 500, 150, writing=False)\n",
    "test_accuracies_preprocessing.append(test_accuracy[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With sample and feature filtering. Replace by median**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original dimensions of the training data set was 250000 samples and 30 columns\n",
      " After feature and sample filtering, there are 223877 samples and 23 columns\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "(labels_raw, data_raw, ids_raw) = load_csv_data(\"data/train.csv\")\n",
    "(t_labels, t_data_raw, t_ids) = load_csv_data(\"data/test.csv\")\n",
    "\n",
    "data_, data_t_, labels = process_data(data_raw, t_data_raw, labels_raw,\n",
    "                                      ids_raw, sample_filtering = True, feature_filtering = True,\n",
    "                                      replace = 'median', remove_outlier=False)\n",
    "\n",
    "# Create train/test split\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_data(data_, labels, ratio=0.8, seed=0)\n",
    "\n",
    "# Add interaction terms and polynomial of degree 2 to cross val set (no bias term is added here\n",
    "# since its done inside crossval function)\n",
    "\n",
    "X_train_int = build_interact_terms(X_train)\n",
    "X_test_int = build_interact_terms(X_test)\n",
    "X_train_poly = build_poly(X_train, 3)\n",
    "X_test_poly = build_poly(X_test, 3)\n",
    "X_train = np.c_[X_train_poly, X_train_int]\n",
    "X_test_forstd = np.c_[X_test_poly, X_test_int]\n",
    "\n",
    "# Create standardizations for the split\n",
    "X_train_std, mean, variance = standardize(X_train)\n",
    "X_test_std = standardize_test(X_test_forstd, mean, variance)\n",
    "\n",
    "\n",
    "# Perform PCA\n",
    "eigVal, eigVec, sumEigVal = PCA(X_train_std, threshold = 0.9)\n",
    "X_train_std = X_train_std.dot(eigVec)\n",
    "X_test_std = X_test_std.dot(eigVec)\n",
    "\n",
    "# Add the bias term for the final models\n",
    "y_train, X_train_std = build_model_data(X_train_std, y_train)\n",
    "y_test, X_test_std = build_model_data(X_test_std, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "initial_w = np.random.rand(X_train_std.shape[1])\n",
    "k_ = 6\n",
    "thresh = 0.5\n",
    "\n",
    "# Perform logistic regression with Newton's Method\n",
    "\n",
    "gen = cross_val(y_train, X_train, k_) # initiate generator object\n",
    "accuracies = []\n",
    "for i in np.arange(k_):\n",
    "    y_tr, x_tr, y_te, x_te = next(gen) # take next subtraining and subtest sets\n",
    "    w = np.random.rand(x_tr.shape[1])\n",
    "    losses, losses_t, acc, acc_t, w = logistic_hessian(y_tr, x_tr, y_te, x_te, w, 0.07, 500, 150, writing=False)\n",
    "    accuracies.append(acc_t[-1])\n",
    "boxplots_preprocessing.append(accuracies)\n",
    "\n",
    "# Perform algorithm on entire training set to retrieve w\n",
    "losses, losses_t, acc, test_accuracy, w = logistic_hessian(y_train, X_train_std, y_test,\n",
    "                                                           X_test_std, initial_w, 0.07, 500, 150, writing=False)\n",
    "test_accuracies_preprocessing.append(test_accuracy[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With sample and feature filtering. Replace by zero**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original dimensions of the training data set was 250000 samples and 30 columns\n",
      " After feature and sample filtering, there are 223877 samples and 23 columns\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "(labels_raw, data_raw, ids_raw) = load_csv_data(\"data/train.csv\")\n",
    "(t_labels, t_data_raw, t_ids) = load_csv_data(\"data/test.csv\")\n",
    "\n",
    "data_, data_t_, labels = process_data(data_raw, t_data_raw, labels_raw,\n",
    "                                      ids_raw, sample_filtering = True, feature_filtering = True,\n",
    "                                      replace = 'zero', remove_outlier=False)\n",
    "\n",
    "# Create train/test split\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_data(data_, labels, ratio=0.8, seed=0)\n",
    "\n",
    "# Add interaction terms and polynomial of degree 2 to cross val set (no bias term is added here\n",
    "# since its done inside crossval function)\n",
    "\n",
    "X_train_int = build_interact_terms(X_train)\n",
    "X_test_int = build_interact_terms(X_test)\n",
    "X_train_poly = build_poly(X_train, 3)\n",
    "X_test_poly = build_poly(X_test, 3)\n",
    "X_train = np.c_[X_train_poly, X_train_int]\n",
    "X_test_forstd = np.c_[X_test_poly, X_test_int]\n",
    "\n",
    "# Create standardizations for the split\n",
    "X_train_std, mean, variance = standardize(X_train)\n",
    "X_test_std = standardize_test(X_test_forstd, mean, variance)\n",
    "\n",
    "\n",
    "# Perform PCA\n",
    "eigVal, eigVec, sumEigVal = PCA(X_train_std, threshold = 0.9)\n",
    "X_train_std = X_train_std.dot(eigVec)\n",
    "X_test_std = X_test_std.dot(eigVec)\n",
    "\n",
    "# Add the bias term for the final models\n",
    "y_train, X_train_std = build_model_data(X_train_std, y_train)\n",
    "y_test, X_test_std = build_model_data(X_test_std, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "initial_w = np.random.rand(X_train_std.shape[1])\n",
    "k_ = 6\n",
    "thresh = 0.5\n",
    "\n",
    "# Perform logistic regression with Newton's Method\n",
    "\n",
    "gen = cross_val(y_train, X_train, k_) # initiate generator object\n",
    "accuracies = []\n",
    "for i in np.arange(k_):\n",
    "    y_tr, x_tr, y_te, x_te = next(gen) # take next subtraining and subtest sets\n",
    "    w = np.random.rand(x_tr.shape[1])\n",
    "    losses, losses_t, acc, acc_t, w = logistic_hessian(y_tr, x_tr, y_te, x_te, w, 0.07, 500, 150, writing=False)\n",
    "    accuracies.append(acc_t[-1])\n",
    "boxplots_preprocessing.append(accuracies)\n",
    "\n",
    "# Perform algorithm on entire training set to retrieve w\n",
    "losses, losses_t, acc, test_accuracy, w = logistic_hessian(y_train, X_train_std, y_test,\n",
    "                                                           X_test_std, initial_w, 0.07, 500, 150, writing=False)\n",
    "test_accuracies_preprocessing.append(test_accuracy[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Without sample and feature filtering. Remove outliers and replace by mean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original dimensions of the training data set was 250000 samples and 30 columns\n",
      " After feature and sample filtering, there are 250000 samples and 30 columns\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "(labels_raw, data_raw, ids_raw) = load_csv_data(\"data/train.csv\")\n",
    "(t_labels, t_data_raw, t_ids) = load_csv_data(\"data/test.csv\")\n",
    "\n",
    "data_, data_t_, labels = process_data(data_raw, t_data_raw, labels_raw,\n",
    "                                      ids_raw, sample_filtering = False, feature_filtering = False,\n",
    "                                      replace = 'mean', remove_outlier=True)\n",
    "\n",
    "# Create train/test split\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_data(data_, labels, ratio=0.8, seed=0)\n",
    "\n",
    "# Add interaction terms and polynomial of degree 2 to cross val set (no bias term is added here\n",
    "# since its done inside crossval function)\n",
    "\n",
    "X_train_int = build_interact_terms(X_train)\n",
    "X_test_int = build_interact_terms(X_test)\n",
    "X_train_poly = build_poly(X_train, 3)\n",
    "X_test_poly = build_poly(X_test, 3)\n",
    "X_train = np.c_[X_train_poly, X_train_int]\n",
    "X_test_forstd = np.c_[X_test_poly, X_test_int]\n",
    "\n",
    "# Create standardizations for the split\n",
    "X_train_std, mean, variance = standardize(X_train)\n",
    "X_test_std = standardize_test(X_test_forstd, mean, variance)\n",
    "\n",
    "\n",
    "# Perform PCA\n",
    "eigVal, eigVec, sumEigVal = PCA(X_train_std, threshold = 0.9)\n",
    "X_train_std = X_train_std.dot(eigVec)\n",
    "X_test_std = X_test_std.dot(eigVec)\n",
    "\n",
    "# Add the bias term for the final models\n",
    "y_train, X_train_std = build_model_data(X_train_std, y_train)\n",
    "y_test, X_test_std = build_model_data(X_test_std, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "initial_w = np.random.rand(X_train_std.shape[1])\n",
    "k_ = 6\n",
    "thresh = 0.5\n",
    "\n",
    "# Perform logistic regression with Newton's Method\n",
    "\n",
    "gen = cross_val(y_train, X_train, k_) # initiate generator object\n",
    "accuracies = []\n",
    "for i in np.arange(k_):\n",
    "    y_tr, x_tr, y_te, x_te = next(gen) # take next subtraining and subtest sets\n",
    "    w = np.random.rand(x_tr.shape[1])\n",
    "    losses, losses_t, acc, acc_t, w = logistic_hessian(y_tr, x_tr, y_te, x_te, w, 0.07, 500, 150, writing=False)\n",
    "    accuracies.append(acc_t[-1])\n",
    "boxplots_preprocessing.append(accuracies)\n",
    "\n",
    "# Perform algorithm on entire training set to retrieve w\n",
    "losses, losses_t, acc, test_accuracy, w = logistic_hessian(y_train, X_train_std, y_test,\n",
    "                                                           X_test_std, initial_w, 0.07, 500, 150, writing=False)\n",
    "test_accuracies_preprocessing.append(test_accuracy[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Without sample and feature filtering. Remove outliers. Replace with median**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original dimensions of the training data set was 250000 samples and 30 columns\n",
      " After feature and sample filtering, there are 250000 samples and 30 columns\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "(labels_raw, data_raw, ids_raw) = load_csv_data(\"data/train.csv\")\n",
    "(t_labels, t_data_raw, t_ids) = load_csv_data(\"data/test.csv\")\n",
    "\n",
    "data_, data_t_, labels = process_data(data_raw, t_data_raw, labels_raw,\n",
    "                                      ids_raw, sample_filtering = False, feature_filtering = False,\n",
    "                                      replace = 'median', remove_outlier=True)\n",
    "\n",
    "# Create train/test split\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_data(data_, labels, ratio=0.8, seed=0)\n",
    "\n",
    "# Add interaction terms and polynomial of degree 2 to cross val set (no bias term is added here\n",
    "# since its done inside crossval function)\n",
    "\n",
    "X_train_int = build_interact_terms(X_train)\n",
    "X_test_int = build_interact_terms(X_test)\n",
    "X_train_poly = build_poly(X_train, 3)\n",
    "X_test_poly = build_poly(X_test, 3)\n",
    "X_train = np.c_[X_train_poly, X_train_int]\n",
    "X_test_forstd = np.c_[X_test_poly, X_test_int]\n",
    "\n",
    "# Create standardizations for the split\n",
    "X_train_std, mean, variance = standardize(X_train)\n",
    "X_test_std = standardize_test(X_test_forstd, mean, variance)\n",
    "\n",
    "\n",
    "# Perform PCA\n",
    "eigVal, eigVec, sumEigVal = PCA(X_train_std, threshold = 0.9)\n",
    "X_train_std = X_train_std.dot(eigVec)\n",
    "X_test_std = X_test_std.dot(eigVec)\n",
    "\n",
    "# Add the bias term for the final models\n",
    "y_train, X_train_std = build_model_data(X_train_std, y_train)\n",
    "y_test, X_test_std = build_model_data(X_test_std, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "initial_w = np.random.rand(X_train_std.shape[1])\n",
    "k_ = 6\n",
    "thresh = 0.5\n",
    "\n",
    "# Perform logistic regression with Newton's Method\n",
    "\n",
    "gen = cross_val(y_train, X_train, k_) # initiate generator object\n",
    "accuracies = []\n",
    "for i in np.arange(k_):\n",
    "    y_tr, x_tr, y_te, x_te = next(gen) # take next subtraining and subtest sets\n",
    "    w = np.random.rand(x_tr.shape[1])\n",
    "    losses, losses_t, acc, acc_t, w = logistic_hessian(y_tr, x_tr, y_te, x_te, w, 0.07, 500, 150, writing=False)\n",
    "    accuracies.append(acc_t[-1])\n",
    "boxplots_preprocessing.append(accuracies)\n",
    "\n",
    "# Perform algorithm on entire training set to retrieve w\n",
    "losses, losses_t, acc, test_accuracy, w = logistic_hessian(y_train, X_train_std, y_test,\n",
    "                                                           X_test_std, initial_w, 0.07, 500, 150, writing=False)\n",
    "test_accuracies_preprocessing.append(test_accuracy[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Without sample and feature removal. Remove outliers. Replace by zero**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original dimensions of the training data set was 250000 samples and 30 columns\n",
      " After feature and sample filtering, there are 250000 samples and 30 columns\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "(labels_raw, data_raw, ids_raw) = load_csv_data(\"data/train.csv\")\n",
    "(t_labels, t_data_raw, t_ids) = load_csv_data(\"data/test.csv\")\n",
    "\n",
    "data_, data_t_, labels = process_data(data_raw, t_data_raw, labels_raw,\n",
    "                                      ids_raw, sample_filtering = False, feature_filtering = False,\n",
    "                                      replace = 'zero', remove_outlier=True)\n",
    "\n",
    "# Create train/test split\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_data(data_, labels, ratio=0.8, seed=0)\n",
    "\n",
    "# Add interaction terms and polynomial of degree 2 to cross val set (no bias term is added here\n",
    "# since its done inside crossval function)\n",
    "\n",
    "X_train_int = build_interact_terms(X_train)\n",
    "X_test_int = build_interact_terms(X_test)\n",
    "X_train_poly = build_poly(X_train, 3)\n",
    "X_test_poly = build_poly(X_test, 3)\n",
    "X_train = np.c_[X_train_poly, X_train_int]\n",
    "X_test_forstd = np.c_[X_test_poly, X_test_int]\n",
    "\n",
    "# Create standardizations for the split\n",
    "X_train_std, mean, variance = standardize(X_train)\n",
    "X_test_std = standardize_test(X_test_forstd, mean, variance)\n",
    "\n",
    "\n",
    "# Perform PCA\n",
    "eigVal, eigVec, sumEigVal = PCA(X_train_std, threshold = 0.9)\n",
    "X_train_std = X_train_std.dot(eigVec)\n",
    "X_test_std = X_test_std.dot(eigVec)\n",
    "\n",
    "# Add the bias term for the final models\n",
    "y_train, X_train_std = build_model_data(X_train_std, y_train)\n",
    "y_test, X_test_std = build_model_data(X_test_std, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "initial_w = np.random.rand(X_train_std.shape[1])\n",
    "k_ = 6\n",
    "thresh = 0.5\n",
    "\n",
    "# Perform logistic regression with Newton's Method\n",
    "\n",
    "gen = cross_val(y_train, X_train, k_) # initiate generator object\n",
    "accuracies = []\n",
    "for i in np.arange(k_):\n",
    "    y_tr, x_tr, y_te, x_te = next(gen) # take next subtraining and subtest sets\n",
    "    w = np.random.rand(x_tr.shape[1])\n",
    "    losses, losses_t, acc, acc_t, w = logistic_hessian(y_tr, x_tr, y_te, x_te, w, 0.07, 500, 150, writing=False)\n",
    "    accuracies.append(acc_t[-1])\n",
    "boxplots_preprocessing.append(accuracies)\n",
    "\n",
    "# Perform algorithm on entire training set to retrieve w\n",
    "losses, losses_t, acc, test_accuracy, w = logistic_hessian(y_train, X_train_std, y_test,\n",
    "                                                           X_test_std, initial_w, 0.07, 500, 150, writing=False)\n",
    "test_accuracies_preprocessing.append(test_accuracy[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create boxplots\n",
    "print(len(boxplots_preprocessing))\n",
    "plt.style.use('seaborn')\n",
    "plt.boxplot(boxplots_preprocessing, labels=['SF/mean', 'SF/median','SF/zero','O/mean','O/median', 'O/zero'])\n",
    "plt.xlabel('Preprocessing Method', weight='bold', fontsize=15)\n",
    "plt.ylabel('Prediction Accuracy', weight='bold', fontsize=15)\n",
    "plt.plot(1, test_accuracies_preprocessing[0], marker='o', c='red')\n",
    "plt.plot(2, test_accuracies_preprocessing[1], marker='o', c='red')\n",
    "plt.plot(3, test_accuracies_preprocessing[2], marker='o', c='red')\n",
    "plt.plot(4, test_accuracies_preprocessing[3], marker='o', c='red')\n",
    "plt.plot(5, test_accuracies_preprocessing[4], marker='o', c='red')\n",
    "plt.plot(6, test_accuracies_preprocessing[5], marker='o', c='red')\n",
    "plt.savefig('Preprocessing.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
