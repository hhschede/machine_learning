{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation of modules and functions\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import datetime\n",
    "import random\n",
    "import warnings\n",
    "warnings.simplefilter(\"error\")\n",
    "\n",
    "# Functions\n",
    "from implementations import *\n",
    "from helpers import *\n",
    "\n",
    "# Autoreload\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loading\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(labels_raw, data_raw, ids_raw) = load_csv_data(\"data/train.csv\")\n",
    "(t_labels, t_data_raw, t_ids) = load_csv_data(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data filtering and standardization\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original dimensions of the training data set was 250000 samples and 30 columns\n",
      " After feature and sample filtering, there are 250000 samples and 23 columns\n"
     ]
    }
   ],
   "source": [
    "data_, data_t_, labels = process_data(data_raw, t_data_raw, labels_raw, ids_raw,sample_filtering = False, feature_filtering = True, replace = 'mean')\n",
    "\n",
    "# Should not standardize all this stuff in the beginning! Only at the very end after the model has been selected!!\n",
    "# Check down two inputs, where the sets are standardized.\n",
    "\n",
    "# data, means, variance = standardize(data_)\n",
    "# need to standardize test using moments calculated from training\n",
    "# data_t = standardize_test(data_t_, means, variance)\n",
    "\n",
    "data = data_.copy()\n",
    "data_t = data_t_.copy()\n",
    "\n",
    "# perform PCA\n",
    "\n",
    "# eigVal, eigVec, sumEigVal = PCA(data, threshold = 0.7)\n",
    "# data = data.dot(eigVec)\n",
    "# data_t = data_t.dot(eigVec)\n",
    "# print(\"we have reduce the number of feature with PCA to {0}\".format(eigVec.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build data into matrix form\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, tx = build_model_data(data, labels)\n",
    "y_t, tx_t = build_model_data(data_t,t_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting into train and test set\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized and randomized samples are found as the variables X_train, y_train, X_test, y_test. Values are split for testing and training sets with the ratio of 0.8\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = split_data(tx, y)\n",
    "\n",
    "# Create the standardized X_train for use of testing the model on the test set. Note that this should\n",
    "# Not be done before crossvalidation, as the crossvalidation function standardizes the sets within the loops\n",
    "\n",
    "X_train_standardized, means, variance = standardize(X_train)\n",
    "X_test_standardized = standardize_test(X_test, means, variance)\n",
    "\n",
    "print('Standardized and randomized samples are found as the variables X_train, y_train, X_test, y_test. Values' +\n",
    "      ' are split for testing and training sets with the ratio of 0.8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression with gradient descent (GD)\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the 4 cross validation test sets is 3.2649763619044094 with variance 0.0007127728951152243. Compare this to the training set mean loss of 3.2641243599992364\n"
     ]
    }
   ],
   "source": [
    "# Initialize w vector\n",
    "initial_w = np.random.rand(X_train.shape[1])\n",
    "k_ = 4\n",
    "\n",
    "# Perform linear regression by gradient descent with cross validation (k=4)\n",
    "test_loss_mean, test_loss_var, vector_test_loss, train_loss_mean, w = least_squares_GD(y_train, X_train, initial_w, gamma = 0.00001, k=k_, max_iters = 2000)\n",
    "\n",
    "# Plot the k trials losses over iterations\n",
    "\n",
    "means_over_time = vector_test_loss.mean(axis=0)\n",
    "error1 = abs(means_over_time - vector_test_loss[0])\n",
    "error2 = abs(means_over_time - vector_test_loss[1])\n",
    "error3 = abs(means_over_time- vector_test_loss[2])\n",
    "error4 = abs(means_over_time - vector_test_loss[3])\n",
    "x = np.arange(len(error1))\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "# for i in np.arange(4):\n",
    "#     plt.plot(x, vector_test_loss[i], label= 'Trial {}'.format(i))\n",
    "plt.plot(x, vector_test_loss[0], label='Trial 1', c='red')\n",
    "plt.fill_between(x, vector_test_loss[0]-error1, vector_test_loss[0]+error1,\n",
    "    alpha=0.2, edgecolor='#CC4F1B', facecolor='#FF9848')\n",
    "plt.plot(x, vector_test_loss[1], label='Trial 2', c = 'green')\n",
    "plt.fill_between(x, vector_test_loss[1] - error2, vector_test_loss[1] + error2, alpha = 0.2, edgecolor='#FF3F1B', facecolor = '#12E99F')\n",
    "plt.plot(x, vector_test_loss[2], label='Trial 3', c='blue')\n",
    "plt.fill_between(x, vector_test_loss[2]-error3, vector_test_loss[2]+error3,\n",
    "    alpha=0.2, edgecolor='#CC4F1B', facecolor='#12E2FF')\n",
    "plt.plot(x, vector_test_loss[3], label='Trial 4', c='purple')\n",
    "plt.fill_between(x, vector_test_loss[3]-error4, vector_test_loss[3]+error4,\n",
    "    alpha=0.2, edgecolor='#CC4F1B', facecolor='#FF00FF')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "# plt.xlim((200, 250))\n",
    "# plt.ylim(10,30)\n",
    "plt.title('Test Set Loss Over Iterations of Gradient Descent')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('The mean of the {} cross validation test sets is {} with variance {}. \\\n",
    "Compare this to the training set mean loss of {}'.format(k_,test_loss_mean, test_loss_var,train_loss_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.56028 0.56273\n"
     ]
    }
   ],
   "source": [
    "# Performing a test for prediction accuracy\n",
    "\n",
    "w = least_squares_GD(y_train, X_train_standardized, initial_w, gamma = 0.00001, k=0, max_iters = 2000)\n",
    "test_pred_lab = predict_labels(w, X_test_standardized)\n",
    "train_pred_lab = predict_labels(w, X_train_standardized)\n",
    "test_accuracy = pred_accuracy(test_pred_lab, y_test)\n",
    "train_accuracy = pred_accuracy(train_pred_lab, y_train)\n",
    "print(test_accuracy, train_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bar chart shows potential variance in the test set. The difference between test and training accuracies is 0.002449999999999952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Percent Accuracy')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAewAAAFJCAYAAABZ+x49AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAHDdJREFUeJzt3XtQ1XX+x/HX4SYCsqGhmZKrRkOX7WIqNalropJjJnRBJbFJbavZMk0SLwjVLwVlu0m72+rqmhCKqK1r02aKbaQ2rLuTZK4VaZa3EPFgiMX1/P6QDrGIh1q+X/vg8zHTDOd75Pt9S873eT7fc8HhcrlcAgAAP2teF3oAAADgGcEGAMAABBsAAAMQbAAADECwAQAwAMEGAMAAPhd6gPMpLa240CP8bISEBMjpPHOhxwAAS3COaxQa2umc21lhG8LHx/tCjwAAluEc5xnBBgDAAAQbAAADEGwAAAxAsAEAMADBBgDAAAQbAAADEGwAAAxAsAEAMADBBgDAAAQbAAADEGwAAAxAsAEAMMDP+rd1AQBab3L6tgs9wkVnxexhth3rogs2/6DtZ+c/aABor7gkDgCAAQg2AAAGINgAABiAYAMAYACCDQCAAQg2AAAGINgAABiAYAMAYACCDQCAAQg2AAAGINgAABiAYAMAYACCDQCAAQg2AAAGINgAABiAYAMAYACCDQCAAQg2AAAGINgAABiAYAMAYACCDQCAAQg2AAAGINgAABiAYAMAYACCDQCAAQg2AAAGINgAABjAx8qdx8TEqFOnTpKknj17aty4cVqwYIG8vb01aNAgPfbYY1YeHgCAdsOyYFdVVUmSsrKy3NvGjh2rzMxMhYWF6Te/+Y327t2ra6+91qoRAABoNyy7JP7JJ5/o22+/1eTJkzVp0iTt2rVL1dXVuuKKK+RwODRo0CB98MEHVh0eAIB2xbIVtr+/v6ZMmaL77rtPBw8e1EMPPaTg4GD3/YGBgTp06NB59xESEiAfH2+rRoRNQkM7XegRAMASdp7fLAt279691atXLzkcDvXu3VudOnVSeXm5+/7KysomAT8Xp/OMVePBRqWlFRd6BACwhBXnt5YeBFh2SXzdunVKT0+XJJWUlOjbb79VQECAvvrqK7lcLm3fvl39+/e36vAAALQrlq2w7733Xs2ZM0cTJkyQw+HQwoUL5eXlpcTERNXV1WnQoEG64YYbrDo8AADtimXB9vPz0/PPP99s+9q1a606JAAA7RYfnAIAgAEINgAABiDYAAAYgGADAGAAgg0AgAEINgAABiDYAAAYgGADAGAAgg0AgAEINgAABiDYAAAYgGADAGAAgg0AgAEINgAABiDYAAAYgGADAGAAgg0AgAEINgAABiDYAAAYgGADAGAAgg0AgAEINgAABiDYAAAYgGADAGAAgg0AgAEINgAABiDYAAAYgGADAGAAgg0AgAEINgAABiDYAAAYgGADAGAAgg0AgAEINgAABiDYAAAYgGADAGAAgg0AgAEINgAABiDYAAAYgGADAGAAgg0AgAEINgAABrA02GVlZfr1r3+t/fv368svv9SECRMUHx+v1NRU1dfXW3loAADaFcuCXVNTo5SUFPn7+0uS0tLSNH36dOXk5Mjlcik/P9+qQwMA0O5YFuxFixZp/Pjx6tq1qyRp7969GjhwoCRpyJAh2rlzp1WHBgCg3fGxYqcbNmxQ586dNXjwYC1dulSS5HK55HA4JEmBgYGqqKjwuJ+QkAD5+HhbMSJsFBra6UKPAACWsPP8Zkmw169fL4fDoQ8++ED79u1TUlKSTp486b6/srJSwcHBHvfjdJ6xYjzYrLTU84MzADCRFee3lh4EWBLs119/3f11QkKCnn76aWVkZKiwsFCRkZEqKCjQLbfcYsWhAQBol2x7W1dSUpIyMzM1btw41dTUKDo62q5DAwBgPEtW2D+UlZXl/jo7O9vqwwEA0C7xwSkAABiAYAMAYACCDQCAAQg2AAAGINgAABiAYAMAYACPwf7oo4/smAMAAJyHx/dhZ2RkqLy8XGPHjtXYsWMVGhpqx1wAAOAHPAY7KytLR44c0caNGzV58mRdfvnlio2NVVRUlHx9fe2YEQCAi16rnsPu0aOHYmJiNGbMGBUXFysrK0t33nmntmzZYvV8AABArVhh5+XlaePGjSotLVVMTIxycnJ02WWXqaSkRLGxsRoxYoQdcwIAcFHzGOxdu3Zp2rRpGjhwYJPt3bp1U2pqqmWDAQCARh4vic+cOVPvvfeeJOnQoUOaNWuWTpw4IUn8xi0AAGziMdiJiYkKCwuTdHZV3b9/f82aNcvywQAAQCOPwS4vL9f48eMlSX5+foqLi5PT6bR8MAAA0MhjsDt27Oi+JC5JO3fuVMeOHS0dCgAANOXxRWfPPPOMnnrqKfdl8O7du2vx4sWWDwYAABp5DPbVV1+tN998U06nU76+vgoKCrJjLgAA8AMeg71792796U9/0pkzZ+RyuVRfX6+jR49q27ZtdswHAADUiuew586dq+HDh6uurk7333+/unXrpuHDh9sxGwAAaOBxhe3n56d77rlHR44cUXBwsBYvXqwxY8bYMRsAAGjgcYXdoUMHlZeXq3fv3ioqKpK3t7fq6ursmA0AADTwGOwHH3xQM2bM0O23366NGzdq9OjRuu666+yYDQAANPB4Sdzf318rVqyQw+HQ+vXrdfDgQUVERNgxGwAAaOBxhZ2RkSGHwyFJCggI0DXXXCMvr1b9Vk4AANBGPK6ww8LCNGfOHN1www3y9/d3b4+JibF0MAAA0MhjsENCQiRJRUVFTbYTbAAA7OMx2GlpaXbMAQAAzsNjsIcNG+Z+DvuH8vPzLRkIAAA05zHYWVlZ7q9ra2u1ZcsWVVdXWzoUAABoyuPLvXv06OH+r1evXpo6daq2bt1qx2wAAKCBxxX2rl273F+7XC4VFxerqqrK0qEAAEBTHoO9ZMkS99cOh0MhISFKT0+3dCgAANBUq57DLisrU5cuXfTtt9/q+PHj6tWrlx2zAQCABh6fw87KytLUqVMlSSdPntQjjzyi3NxcywcDAACNPAY7NzdXr7/+uqSzL0DbsGGDsrOzLR8MAAA08hjsmpoa+fn5uW/7+vpaOhAAAGjO43PYw4cP1wMPPKBRo0bJ4XBo8+bNioqKsmM2AADQwGOwn3rqKb399tvatWuXfHx8NGnSJA0fPtyO2QAAQAOPl8RLSkq0Z88ezZ8/XxMnTtQ777yjEydO2DEbAABo4DHYiYmJCgsLkyR169ZN/fv316xZsywfDAAANPIY7FOnTmn8+PGSJD8/P8XFxcnpdFo+GAAAaOQx2P7+/nrvvffct3fu3KmOHTtaOhQAAGjK44vOnn32WSUmJrovg3fv3l0ZGRked1xXV6fk5GR98cUX8vb2Vlpamlwul2bPni2Hw6Hw8HClpqbKy8vjYwYAAC56HoMdERGhN998U06nU76+vgoKCtL27dsVHh5+3u979913JUlr1qxRYWGhO9jTp09XZGSkUlJSlJ+frxEjRrTN3wQAgHbMY7C/53K5tHr1aq1du1ZVVVUqKCg4758fPny4hg4dKkk6evSoLr30Uv3jH//QwIEDJUlDhgzRjh07CDYAAK3gMdiFhYVas2aNtm7dKofDoWeeeUZ33nln63bu46OkpCRt2bJFS5Ys0bvvviuHwyFJCgwMVEVFxXm/PyQkQD4+3q06Fn6+QkM7XegRAMASdp7fWgz2ypUrlZubK19fX40aNUpPPPGEJk+erNjY2B91gEWLFikxMVFxcXFNfo92ZWWlgoODz/u9TueZH3Us/DyVlp7/gRkAmMqK81tLDwJaDPYLL7ygqKgoxcfHq3///nI4HO7VcWv89a9/VUlJiR5++GF17NhRDodD1113nQoLCxUZGamCggLdcsstP/5vAgDARajFYBcUFGjTpk1auHChTpw4oVGjRqm6urrVOx45cqTmzJmj+++/X7W1tZo7d6769u2r+fPn64UXXlCfPn0UHR3dJn8JAADauxaDfckllyghIUEJCQn65JNPtH79etXW1mr06NGKj4/X/ffff94dBwQE6OWXX262nV/NCQDAj9eqN0FHRERo3rx5Kigo0LRp0/T+++9bPRcAAPiBVr+tSzr7u7Cjo6O5lA0AgM34mDEAAAxAsAEAMIDHYD/++OPNtj3wwAOWDAMAAM6txeewH3vsMe3bt0/Hjx9XVFSUe3tdXZ0uu+wyW4YDAABntRjs9PR0lZeXa8GCBUpOTm78Bh8fdenSxZbhAADAWS0GOygoSEFBQfrjH/+o4uJinTp1Si6XS5L01VdfacCAAbYNCQDAxa5Vvw9727ZtCgsLc29zOBxatWqVpYMBAIBGHoO9fft2vf322/L397djHgAAcA4eXyUeFhbmvhQOAAAuDI8r7F/84hcaPXq0brrpJvn5+bm3p6WlWToYAABo5DHYgwcP1uDBg+2YBQAAtMBjsGNjY3X48GF9/vnnGjRokI4dO9bkBWgAAMB6Hp/Dfuutt/Too49qwYIFOnXqlMaPH6+NGzfaMRsAAGjgMdjLli3T6tWrFRgYqC5duuiNN97Q0qVL7ZgNAAA08BhsLy8vBQUFuW937dpVXl78zhAAAOzk8Tns8PBwZWdnq7a2Vvv27VNOTo4iIiLsmA0AADTwuFROSUlRSUmJOnTooHnz5ikoKEipqal2zAYAABp4XGF36NBBN954o2bOnKmTJ09q27ZtCgwMtGM2AADQwOMKOzk5We+88477dmFhIStsAABs5nGF/fHHH2vTpk2SpM6dOysjI0NjxoyxfDAAANDI4wq7vr5ex48fd98uKyvjVeIAANjM4wr7kUceUWxsrG6++WZJUlFRkebNm2f5YAAAoFGr3ta1YcMG7d69Wz4+PkpOTlbXrl3tmA0AADTwGOwZM2bo73//u6Kjo+2YBwAAnIPHYF955ZV65ZVXdMMNN8jf39+9fcCAAZYOBgAAGnkMdnl5uQoLC1VYWOje5nA4tGrVKksHAwAAjTwGOysry445AADAeXh8f9aRI0f04IMPauTIkSotLdWkSZN0+PBhO2YDAAANWvVZ4lOmTFFAQIAuvfRS3XnnnUpKSrJjNgAA0MBjsJ1OpwYNGiTp7HPXcXFxOn36tOWDAQCARh6D7e/vr6+//loOh0OS9K9//Ut+fn6WDwYAABp5fNHZ7Nmz9fDDD+urr77S2LFjderUKb388st2zAYAABp4DPb111+vdevW6eDBg6qrq1OfPn1YYQMAYLMWg11SUqLFixeruLhYN910k2bOnKng4GA7ZwMAAA1afA577ty56tq1q5588klVV1crLS3NzrkAAMAPnHeFvXz5cknSbbfdppiYGNuGAgAATbW4wvb19W3y9Q9vAwAAe3l8W9f3vn9bFwAAsF+Ll8SLi4sVFRXlvl1SUqKoqCi5XC45HA7l5+fbMiAAADhPsDdv3mznHAAA4DxaDHaPHj3+px3X1NRo7ty5OnLkiKqrq/Xoo4/qyiuv1OzZs+VwOBQeHq7U1FR5ebX6qjwAABctjx+c8lP97W9/0yWXXKKMjAw5nU7FxsYqIiJC06dPV2RkpFJSUpSfn68RI0ZYNQIAAO2GZcvbO+64Q0888YT7tre3t/bu3auBAwdKkoYMGaKdO3dadXgAANoVy4IdGBiooKAgnT59WtOmTdP06dPdL1j7/v6KigqrDg8AQLti2SVxSTp27Jh++9vfKj4+XmPGjFFGRob7vsrKSo8fdRoSEiAfH28rR4QNQkM7XegRAMASdp7fLAv2iRMnNHnyZKWkpOjWW2+VJF1zzTUqLCxUZGSkCgoKdMstt5x3H07nGavGg41KS7mSAqB9suL81tKDAMsuib/66qv65ptv9Ic//EEJCQlKSEjQ9OnTlZmZqXHjxqmmpkbR0dFWHR4AgHbFshV2cnKykpOTm23Pzs626pAAALRbvAkaAAADEGwAAAxAsAEAMADBBgDAAAQbAAADEGwAAAxAsAEAMADBBgDAAAQbAAADEGwAAAxAsAEAMADBBgDAAAQbAAADEGwAAAxAsAEAMADBBgDAAAQbAAADEGwAAAxAsAEAMADBBgDAAAQbAAADEGwAAAxAsAEAMADBBgDAAAQbAAADEGwAAAxAsAEAMADBBgDAAAQbAAADEGwAAAxAsAEAMADBBgDAAAQbAAADEGwAAAxAsAEAMADBBgDAAAQbAAADEGwAAAxAsAEAMADBBgDAAAQbAAADEGwAAAxAsAEAMIClwS4qKlJCQoIk6csvv9SECRMUHx+v1NRU1dfXW3loAADaFcuCvWzZMiUnJ6uqqkqSlJaWpunTpysnJ0cul0v5+flWHRoAgHbHsmBfccUVyszMdN/eu3evBg4cKEkaMmSIdu7cadWhAQBod3ys2nF0dLQOHz7svu1yueRwOCRJgYGBqqio8LiPkJAA+fh4WzUibBIa2ulCjwAAlrDz/GZZsP+bl1fjYr6yslLBwcEev8fpPGPlSLBJaannB2cAYCIrzm8tPQiw7VXi11xzjQoLCyVJBQUF6t+/v12HBgDAeLYFOykpSZmZmRo3bpxqamoUHR1t16EBADCepZfEe/bsqbVr10qSevfurezsbCsPBwBAu8UHpwAAYACCDQCAAQg2AAAGINgAABiAYAMAYACCDQCAAQg2AAAGINgAABiAYAMAYACCDQCAAQg2AAAGINgAABiAYAMAYACCDQCAAQg2AAAGINgAABiAYAMAYACCDQCAAQg2AAAGINgAABiAYAMAYACCDQCAAQg2AAAGINgAABiAYAMAYACCDQCAAQg2AAAGINgAABiAYAMAYACCDQCAAQg2AAAGINgAABiAYAMAYACCDQCAAQg2AAAGINgAABiAYAMAYACCDQCAAQg2AAAGINgAABiAYAMAYACCDQCAAQg2AAAG8LHzYPX19Xr66af16aefys/PT88995x69epl5wgAABjJ1hX21q1bVV1drdzcXM2cOVPp6el2Hh4AAGPZGux///vfGjx4sCTpxhtv1Mcff2zn4QEAMJatl8RPnz6toKAg921vb2/V1tbKx+fcY4SGdmrzGTY9P7bN9wkAPwec39o3W1fYQUFBqqysdN+ur69vMdYAAKCRrcHu16+fCgoKJEm7d+/WVVddZefhAQAwlsPlcrnsOtj3rxL/7LPP5HK5tHDhQvXt29euwwMAYCxbgw0AAH4aPjgFAAADEGwAAAzAS7R/hPT0dO3du1elpaX67rvvFBYWppCQEC1ZsqTV+zh8+LCKi4t1++23N7vv2LFjio6O1vPPP68RI0a05egAcE7/y3lt3759ys/P12OPPdbq4z3yyCOSpFdfffUnz3yx4jnsn2DDhg06cOCAEhMTf/T35uXl6fDhw5oxY0az+1555RVVVVVpz549WrlyZRtMCgCt87+c11rr2LFjSkpKUk1NjRYvXqywsDDLjtUescJuI4sXL9aHH36o+vp6TZkyRSNHjtSqVau0adMmeXl5acCAAZo2bZr+/Oc/q7q6WjfddJOGDh3q/v76+npt2rRJubm5mjp1qvbv36++ffvqzJkzmjNnjr7++mvV1NQoNTVV4eHhzbZ99tln7gcClZWViomJ0ZYtWzRhwgR169ZN33zzjV544QWlpKTo9OnTcjqdmjBhguLi4vThhx8qLS1NLpdL3bt317x58zRx4kRt3rxZXl5eSk9P180338yqH7iIFBYW6ne/+518fX0VFxcnf39/vf766+77X375ZRUXF2vNmjV68cUXNXLkSPXr109ffPGFunTposzMTHl7ezfZ57p16xQVFSV/f3/l5OQoKSlJ0tmFzOrVq1VfX6+oqCg9/vjj59x22223aceOHZKkGTNmaPz48Tpy5IjWr1+v+vp6TZs2Tfv379c777yj2tpaderUSZmZmaqvr9ecOXN09OhR1dTUaP78+crOztaYMWM0dOhQ7d+/X4sWLdLSpUvt+wH/BDyH3Qa2bdumkpISrV69Wq+99poyMzN1+vRpbdiwQSkpKVqzZo26d+8ub29vTZ06VXfddVeTWEvS9u3bde211+qSSy7RPffco5ycHElSTk6OfvnLXyo3N1cLFy7URx99dM5t53PXXXdpxYoVOnTokPvr3//+9/rLX/4iSUpJSVF6erry8vI0YMAAOZ1OXX/99dq5c6dqamq0Y8eOZvMCaP+qqqqUk5OjmJgYHTx4UEuXLlVWVpZ69+6t7du3N/mzhw4d0hNPPKHc3FydPHlSe/bsaXJ/fX293nzzTY0dO1ajR4/WW2+9pe+++05lZWVatmyZcnJytGHDBlVUVOjo0aPNtv3wQ7f+W3BwsFavXq3IyEiVl5dr5cqVysnJUW1trfbs2aM1a9aoR48eys3NVXp6uoqKinTffffpjTfekHT2gcS9997b9j/ANsYKuw189tln+vjjj5WQkCBJqqur09GjR7Vo0SKtWLFCR44cUb9+/XS+Zx/y8vJ09OhRTZkyRTU1Nfr00081Y8YMffHFF+6VbUREhCIiIjRv3rxm2/Ly8tz7+u/j9O7dW5J06aWXKisrS5s3b1ZAQIBqa2slSU6nU3369JEk998hLi5Oa9eu1XfffafBgwfL19e3LX5UAAzy/blDkrp06aKkpCQFBgbqwIEDuvHGG5v82ZCQEHXv3l2S1L17d1VVVTW5//3331dlZaVmzpwpqfGqYnh4uMLDw+Xv7y9Jmjt3rnbv3t1s23/74Xnu+zm9vLzk6+urJ598UgEBAfr6669VW1urAwcOaMiQIZKkq666SldddZVcLpcWLFigsrIy7dixQ08++eT/9LOyAyvsNtCnTx/deuutysrK0sqVK3XHHXeoZ8+eysvL0//93/8pOztbRUVFKioqksPhaBbUsrIy7d27V3l5eVq+fLlWrVqlYcOGaePGjerbt6/7kerBgwf11FNPnXObn5+fSktLJUn/+c9/muzfy+vs/+bly5erf//+ysjI0MiRI91zdO7cWYcOHZJ09oUg+fn5ioyM1P79+7V+/XojHnkCaHvfnzsqKiq0ZMkSvfjii3ruuefUoUOHZucxh8Nx3n2tW7dOzz33nJYvX67ly5frpZdeUk5Ojq644godOHBA1dXVkqRp06YpNDS02baSkhLV1taqsrJS1dXV+vzzz5vN+cknn2jr1q166aWXNH/+fNXX18vlcjU5Zx46dEgzZ86Uw+HQmDFjtGDBAt12221GLEpYYbeBESNG6J///Kfi4+N15swZRUdHKyAgQH379tU999zjfuT5q1/9Sn5+flq2bJmuvvpqjRo1StLZF3vccccd7n90knTfffdp/vz5WrdunebOnauJEyeqrq5OycnJ6tOnT7NtPXr00Nq1axUfH6/rrrtOHTt2bDbnsGHD9Mwzz+iNN95Q586d5XA4VF1drWeffVZJSUny8vJSt27dNHnyZEnS6NGj9e6777pX3wAuTkFBQerXr59iY2MVEBCg4OBgHT9+XD179mzV95eVlamoqEgvvviie9vNN9+sqqoqHTx4UA899JAmTpwoh8Oh22+/XT169Gi2rVu3bpo0aZLGjRunnj176vLLL292nF69eqljx466++675efnp9DQUB0/flzjx49vcs78fsV+9913a+jQodq4cWPb/KAsxqvE0aJXX31Vl112mWJiYi70KADQ5kpKSjRr1iy99tprF3qUVuGSOM4pMTFRu3fv1ujRoy/0KADQ5jZv3qypU6e6n1M3AStsAAAMwAobAAADEGwAAAxAsAEAMADBBgDAAAQbAAADEGwAAAzw/8K1u0cI37EsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot bar chart\n",
    "\n",
    "print('The bar chart shows potential variance in the test set. \\\n",
    "The difference between test and training accuracies is {}'.format(train_accuracy - test_accuracy))\n",
    "names = ['Test Accuracy', 'Train Accuracy']\n",
    "values = [test_accuracy * 100, train_accuracy * 100]\n",
    "plt.style.use('seaborn')\n",
    "plt.bar(names, values, width = 0.3, yerr = [test_loss_var, 0])\n",
    "plt.ylabel('Percent Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression with stochastic gradient descent (SGD)\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial_w = np.ones(X_train.shape[1])\n",
    "initial_w = np.random.rand(X_train.shape[1])\n",
    "losses, ws = least_squares_SGD(y_train, X_train, initial_w, max_iters = 250, tol = 1e-4, patience = 5) # fit model, retrieve parameters ws\n",
    "test_losses = list(map(lambda x: compute_loss(y_test, X_test, x, method = 'MSE'), ws)) # retrieve losses using test set with ws\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "plt.plot(losses, label='Training set loss', c='blue')\n",
    "plt.plot(test_losses, label='Test set loss', c='red')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Cost Function Loss Over Iterations of Stochastic Gradient Descent')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Make plot with label prediction accuracy\n",
    "\n",
    "pred_ytrain = list(map(lambda x: predict_labels(x, X_train), ws)) # Training prediction\n",
    "pred_accuracytrain = list(map(lambda x: pred_accuracy(x, y_train), pred_ytrain))\n",
    "pred_ytest = list(map(lambda x: predict_labels(x, X_test), ws)) # Test prediction\n",
    "pred_accuracytest = list(map(lambda x: pred_accuracy(x, y_test), pred_ytest))\n",
    "\n",
    "\n",
    "plt.plot(pred_accuracytrain, label='Training set prediction accuracy', c='blue')\n",
    "plt.plot(pred_accuracytest, label='Test set prediction accuracy', c='red')\n",
    "plt.legend()\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Prediction Accuracy')\n",
    "plt.title('Prediction Accuracy Over Iterations of Stochastic Gradient Descent')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression using least squares normal equations\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bar chart shows potential variance in the test set. The difference between test and training accuracies is 0.0023849999999999705\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k_ = 4\n",
    "test_loss_mean, test_loss_var, train_loss_mean, w_ = least_squares(y_train, X_train, k_)\n",
    "\n",
    "w = least_squares(y_train, X_train, k =0)\n",
    "test_pred_lab = predict_labels(w, X_test_standardized)\n",
    "train_pred_lab = predict_labels(w, X_train_standardized)\n",
    "test_accuracy = pred_accuracy(test_pred_lab, y_test)\n",
    "train_accuracy = pred_accuracy(train_pred_lab, y_train)\n",
    "# Two subplots, the axes array is 1-d\n",
    "\n",
    "print('The bar chart shows potential variance in the test set. \\\n",
    "The difference between test and training accuracies is {}'.format(train_accuracy - test_accuracy))\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "plt.bar(['Testing Prediction Accuracy', 'Training Prediction Accuracy'], [test_accuracy * 100, train_accuracy * 100], width=0.3, yerr=[test_loss_var, 0])\n",
    "plt.title('Testing Set')\n",
    "plt.show()\n",
    "plt.bar(['Test Set Loss', 'Training Set Loss'], [test_loss_mean, train_loss_mean], width=0.3, yerr=[test_loss_var, 0])\n",
    "plt.title('Cross Validation Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression using the normal equations with additional polynomial degrees\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = range(1,15)\n",
    "rmse_tr = np.zeros(len(degrees))\n",
    "rmse_ts = np.zeros(len(degrees))\n",
    "pred_tr = np.zeros(len(degrees))\n",
    "pred_ts = np.zeros(len(degrees))\n",
    "\n",
    "\n",
    "for ind, degree in enumerate(degrees):\n",
    "    #train the model\n",
    "    X_test_poly = build_poly(X_test,degree)\n",
    "    X_train_poly = build_poly(X_train,degree)\n",
    "    w = least_squares(y_train, X_train_poly)\n",
    "    rmse_tr[ind] = (np.sqrt(2 * compute_loss(y_train, X_train_poly, w)))\n",
    "    pred_tr[ind] = pred_accuracy(predict_labels(w,X_train_poly),y_train)\n",
    "    \n",
    "    #test the model\n",
    "    \n",
    "    rmse_ts[ind] = (np.sqrt(2 * compute_loss(y_test, X_test_poly, w)))\n",
    "    pred_ts[ind] = (pred_accuracy(predict_labels(w, X_test_poly),y_test))\n",
    "    \n",
    "    # print the update\n",
    "    print(\"degree: {d} \\t rmse_ts: {a} \\t  pred_ts: {b}\".format(d = degree, a = rmse_ts[ind], b = pred_ts[ind]))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# plot the loss\n",
    "plt.style.use('seaborn')\n",
    "plt.plot(degrees,rmse_tr, c='blue')\n",
    "plt.plot(degrees,rmse_ts, c='red')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['training set', 'testing set'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#plot the accuracy\n",
    "plt.style.use('seaborn')\n",
    "plt.plot(degrees,pred_tr, c='blue')\n",
    "plt.plot(degrees,pred_ts, c='red')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['training set', 'testing set'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression using ridge regression\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = np.logspace(-5, 0, 15)\n",
    "rmse_tr = []\n",
    "rmse_ts = []\n",
    "pred_tr = []\n",
    "pred_ts = []\n",
    "\n",
    "for ind, lambda_ in enumerate(lambdas):\n",
    "    \n",
    "    w = ridge_regression(y_train, X_train, lambda_)\n",
    "    rmse_tr.append(np.sqrt(2 * compute_loss(y_train, X_train, w)))\n",
    "    pred_tr.append(pred_accuracy(predict_labels(w, X_train),y_train))\n",
    "    \n",
    "    \n",
    "    rmse_ts.append(np.sqrt(2 * compute_loss(y_test, X_test, w)))\n",
    "    pred_ts.append(pred_accuracy(predict_labels(w, X_test),y_test))\n",
    "    \n",
    "plt.style.use('seaborn')\n",
    "plt.semilogx(lambdas,rmse_tr, c='blue')\n",
    "plt.semilogx(lambdas,rmse_ts, c='red')\n",
    "plt.legend(['training set', 'testing set'], loc='upper left')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "plt.semilogx(lambdas,pred_tr, c='blue')\n",
    "plt.semilogx(lambdas,pred_ts, c='red')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['training set', 'testing set'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# print(np.max(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression using gradient descent and stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[y_train == -1] = 0\n",
    "y_test[y_test == -1] = 0\n",
    "y[y == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "initial_w = np.random.rand(X_train.shape[1])\n",
    "losses, ws = logistic_regression(y_train, X_train, initial_w, method = 'gd', max_iters = 2000, gamma = 0.0005) # fit model, retrieve parameters ws\n",
    "test_losses = list(map(lambda x: compute_loss(y_test, X_test, x, lam = 0, method = \"logistic\"), ws)) # retrieve losses using test set with ws\n",
    "\n",
    "\n",
    "\n",
    "# Make plot with label prediction accuracy\n",
    "\n",
    "pred_ytrain = list(map(lambda x: predict_labels_logistic(x, X_train), ws)) # Training prediction\n",
    "pred_accuracytrain = list(map(lambda x: pred_accuracy(x, y_train), pred_ytrain))\n",
    "pred_ytest = list(map(lambda x: predict_labels_logistic(x, X_test), ws)) # Test prediction\n",
    "pred_accuracytest = list(map(lambda x: pred_accuracy(x, y_test), pred_ytest))\n",
    "\n",
    "\n",
    "plotCurves(losses, pred_accuracytrain, test_losses, pred_accuracytest, \"Logistic Regression\")\n",
    "\n",
    "\"\"\"\n",
    "plt.style.use('seaborn')\n",
    "plt.plot(losses, label='Training set loss', c='blue')\n",
    "plt.plot(test_losses, label='Test set loss', c='red')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Logistic Regression: Cost Function Loss Over Iterations of Stochastic Gradient Descent')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(pred_accuracytrain, label='Training set prediction accuracy', c='blue')\n",
    "plt.plot(pred_accuracytest, label='Test set prediction accuracy', c='red')\n",
    "plt.legend()\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Prediction Accuracy')\n",
    "plt.title('Logistic Regression Prediction Accuracy Over Iterations of Gradient Descent')\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sample = y[:10000] \n",
    "tx_sample = tx[:10000,:]\n",
    "\n",
    "X_train_sample, y_train_sample, X_test_sample, y_test_sample = split_data(tx_sample, y_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent with varying learning rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_iter = 10000\n",
    "\n",
    "lr = [0.00001,0.00005,0.0001,0.0005,0.001] \n",
    "\n",
    "\n",
    "test_losses  = np.zeros([len(lr),(num_iter+1)])\n",
    "test_acc = np.zeros([len(lr),(num_iter+1)])\n",
    "train_losses = np.zeros([len(lr),(num_iter)])\n",
    "train_acc= np.zeros([len(lr),(num_iter+1)])\n",
    "\n",
    "initial_w = np.random.rand(X_train.shape[1])\n",
    "\n",
    "for i in range(len(lr)):\n",
    "    \n",
    "    l_tr, ws = logistic_regression(y_train_sample, X_train_sample, initial_w, max_iters = num_iter, gamma = lr[i], method = 'gd') # fit model, retrieve parameters ws\n",
    "    train_losses[i,:] = np.array(l_tr)\n",
    "    l_ts = list(map(lambda x: compute_loss(y_test_sample, X_test_sample, x, lam = 0, method = \"logistic\"), ws)) # retrieve losses using test set with ws\n",
    "    test_losses[i,:] = np.array(l_ts)\n",
    "    pred_ytrain = list(map(lambda x: predict_labels_logistic(x, X_train_sample), ws)) # Training prediction\n",
    "    train_acc[i,:] = list(map(lambda x: pred_accuracy(x, y_train_sample), pred_ytrain))\n",
    "    pred_ytest = list(map(lambda x: predict_labels_logistic(x, X_test_sample), ws)) # Test prediction\n",
    "    test_acc[i,:] = list(map(lambda x: pred_accuracy(x, y_test_sample), pred_ytest))\n",
    "\n",
    "for i in range(len(lr)):\n",
    "    titre = \"learning rate \"+str(lr[i])\n",
    "    plotCurves(train_losses[i,:], train_acc[i,:], test_losses[i,:], test_acc[i,:], titre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iter = 1000\n",
    "\n",
    "lr = [0.00001,0.00005,0.0001,0.0005,0.001] \n",
    "\n",
    "\n",
    "test_losses  = np.zeros([len(lr),(num_iter+1)])\n",
    "test_acc = np.zeros([len(lr),(num_iter+1)])\n",
    "train_losses = np.zeros([len(lr),(num_iter)])\n",
    "train_acc= np.zeros([len(lr),(num_iter+1)])\n",
    "\n",
    "initial_w = np.random.rand(X_train.shape[1])\n",
    "\n",
    "for i in range(len(lr)):\n",
    "    \n",
    "    l_tr, ws = logistic_regression(y_train_sample, X_train_sample, initial_w, max_iters = num_iter, gamma = lr[i], method = 'gd') # fit model, retrieve parameters ws\n",
    "    train_losses[i,:] = np.array(l_tr)\n",
    "    l_ts = list(map(lambda x: compute_loss(y_test_sample, X_test_sample, x, lam = 0, method = \"logistic\"), ws)) # retrieve losses using test set with ws\n",
    "    test_losses[i,:] = np.array(l_ts)\n",
    "    pred_ytrain = list(map(lambda x: predict_labels_logistic(x, X_train_sample), ws)) # Training prediction\n",
    "    train_acc[i,:] = list(map(lambda x: pred_accuracy(x, y_train_sample), pred_ytrain))\n",
    "    pred_ytest = list(map(lambda x: predict_labels_logistic(x, X_test_sample), ws)) # Test prediction\n",
    "    test_acc[i,:] = list(map(lambda x: pred_accuracy(x, y_test_sample), pred_ytest))\n",
    "\n",
    "for i in range(len(lr)):\n",
    "    titre = \"learning rate \"+str(lr[i])\n",
    "    plotCurves(train_losses[i,:], train_acc[i,:], test_losses[i,:], test_acc[i,:], titre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iter = 20000\n",
    "\n",
    "lr = [0.00005,0.0001] \n",
    "\n",
    "\n",
    "test_losses  = np.zeros([len(lr),(num_iter+1)])\n",
    "test_acc = np.zeros([len(lr),(num_iter+1)])\n",
    "train_losses = np.zeros([len(lr),(num_iter)])\n",
    "train_acc= np.zeros([len(lr),(num_iter+1)])\n",
    "\n",
    "initial_w = np.random.rand(X_train.shape[1])\n",
    "\n",
    "for i in range(len(lr)):\n",
    "    \n",
    "    l_tr, ws = logistic_regression(y_train_sample, X_train_sample, initial_w, max_iters = num_iter, gamma = lr[i], method = 'gd') # fit model, retrieve parameters ws\n",
    "    train_losses[i,:] = np.array(l_tr)\n",
    "    l_ts = list(map(lambda x: compute_loss(y_test_sample, X_test_sample, x, lam = 0, method = \"logistic\"), ws)) # retrieve losses using test set with ws\n",
    "    test_losses[i,:] = np.array(l_ts)\n",
    "    pred_ytrain = list(map(lambda x: predict_labels_logistic(x, X_train_sample), ws)) # Training prediction\n",
    "    train_acc[i,:] = list(map(lambda x: pred_accuracy(x, y_train_sample), pred_ytrain))\n",
    "    pred_ytest = list(map(lambda x: predict_labels_logistic(x, X_test_sample), ws)) # Test prediction\n",
    "    test_acc[i,:] = list(map(lambda x: pred_accuracy(x, y_test_sample), pred_ytest))\n",
    "\n",
    "for i in range(len(lr)):\n",
    "    titre = \"learning rate \"+str(lr[i])\n",
    "    plotCurves(train_losses[i,:], train_acc[i,:], test_losses[i,:], test_acc[i,:], titre)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent with varying learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_iter = 10000\n",
    "\n",
    "lr = [0.00001,0.00005,0.0001,0.0005,0.001] \n",
    "\n",
    "\n",
    "test_losses  = np.zeros([len(lr),(num_iter+1)])\n",
    "test_acc = np.zeros([len(lr),(num_iter+1)])\n",
    "train_losses = np.zeros([len(lr),(num_iter)])\n",
    "train_acc= np.zeros([len(lr),(num_iter+1)])\n",
    "\n",
    "initial_w = np.random.rand(X_train.shape[1])\n",
    "\n",
    "for i in range(len(lr)):\n",
    "    \n",
    "    l_tr, ws = logistic_regression(y_train_sample, X_train_sample, initial_w, max_iters = num_iter, gamma = lr[i], method = 'sgd') # fit model, retrieve parameters ws\n",
    "    train_losses[i,:] = np.array(l_tr)\n",
    "    l_ts = list(map(lambda x: compute_loss(y_test_sample, X_test_sample, x, lam = 0, method = \"logistic\"), ws)) # retrieve losses using test set with ws\n",
    "    test_losses[i,:] = np.array(l_ts)\n",
    "    pred_ytrain = list(map(lambda x: predict_labels(x, X_train_sample), ws)) # Training prediction\n",
    "    train_acc[i,:] = list(map(lambda x: pred_accuracy(x, y_train_sample), pred_ytrain))\n",
    "    pred_ytest = list(map(lambda x: predict_labels(x, X_test_sample), ws)) # Test prediction\n",
    "    test_acc[i,:] = list(map(lambda x: pred_accuracy(x, y_test_sample), pred_ytest))\n",
    "\n",
    "for i in range(len(lr)):\n",
    "    titre = \"learning rate \"+str(lr[i])\n",
    "    plotCurves(train_losses[i,:], train_acc[i,:], test_losses[i,:], test_acc[i,:], titre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_iter = 20000\n",
    "\n",
    "lr = [0.00005,0.0001,0.0005] \n",
    "\n",
    "\n",
    "test_losses  = np.zeros([len(lr),(num_iter+1)])\n",
    "test_acc = np.zeros([len(lr),(num_iter+1)])\n",
    "train_losses = np.zeros([len(lr),(num_iter)])\n",
    "train_acc= np.zeros([len(lr),(num_iter+1)])\n",
    "\n",
    "initial_w = np.random.rand(X_train.shape[1])\n",
    "\n",
    "for i in range(len(lr)):\n",
    "    \n",
    "    l_tr, ws = logistic_regression(y_train_sample, X_train_sample, initial_w, max_iters = num_iter, gamma = lr[i], method = 'sgd') # fit model, retrieve parameters ws\n",
    "    train_losses[i,:] = np.array(l_tr)\n",
    "    l_ts = list(map(lambda x: compute_loss(y_test_sample, X_test_sample, x, lam = 0, method = \"logistic\"), ws)) # retrieve losses using test set with ws\n",
    "    test_losses[i,:] = np.array(l_ts)\n",
    "    pred_ytrain = list(map(lambda x: predict_labels(x, X_train_sample), ws)) # Training prediction\n",
    "    train_acc[i,:] = list(map(lambda x: pred_accuracy(x, y_train_sample), pred_ytrain))\n",
    "    pred_ytest = list(map(lambda x: predict_labels(x, X_test_sample), ws)) # Test prediction\n",
    "    test_acc[i,:] = list(map(lambda x: pred_accuracy(x, y_test_sample), pred_ytest))\n",
    "    \n",
    "for i in range(len(lr)):\n",
    "    titre = \"learning rate \"+str(lr[i])\n",
    "    plotCurves(train_losses[i,:], train_acc[i,:], test_losses[i,:], test_acc[i,:], titre)\n",
    "    print(\"best test accuracy = {0}\".format(max(test_acc[i,:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression using Newton's method\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_w = np.random.rand(X_train.shape[1])\n",
    "# losses, ws = logistic_hessian(y_train, X_train, initial_w) # fit model, retrieve parameters ws\n",
    "# test_losses = list(map(lambda x: compute_loss(y_test, X_test, x, method = 'MSE'), ws)) # retrieve losses using test set with ws\n",
    "\n",
    "# plt.style.use('seaborn')\n",
    "# plt.plot(losses, label='Training set loss', c='blue')\n",
    "# plt.plot(test_losses, label='Test set loss', c='red')\n",
    "# plt.xlabel('Iteration')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Logistic Regression: Cost Function Loss Over Iterations of Stochastic Gradient Descent')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # Make plot with label prediction accuracy\n",
    "\n",
    "# pred_ytrain = list(map(lambda x: predict_labels(x, X_train), ws)) # Training prediction\n",
    "# pred_accuracytrain = list(map(lambda x: pred_accuracy(x, y_train), pred_ytrain))\n",
    "# pred_ytest = list(map(lambda x: predict_labels(x, X_test), ws)) # Test prediction\n",
    "# pred_accuracytest = list(map(lambda x: pred_accuracy(x, y_test), pred_ytest))\n",
    "\n",
    "\n",
    "# plt.plot(pred_accuracytrain, label='Training set prediction accuracy', c='blue')\n",
    "# plt.plot(pred_accuracytest, label='Test set prediction accuracy', c='red')\n",
    "# plt.legend()\n",
    "# plt.xlabel('Iteration')\n",
    "# plt.ylabel('Prediction Accuracy')\n",
    "# plt.title('Logistic Regression Prediction Accuracy Over Iterations of Gradient Descent')\n",
    "# plt.show()\n",
    "\n",
    "\"\"\"IF YOU READ THIS: I tried doing something here so that LR is faster and more accurate,\n",
    "the problem is that we can't calculate things that way, it's too big, but maybe I'll find a way\n",
    "another time.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = np.logspace(-10,0, 11)\n",
    "loss_tr = []\n",
    "loss_ts = []\n",
    "pred_tr = []\n",
    "pred_ts = []\n",
    "initial_w = np.random.rand(X_train.shape[1])\n",
    "\n",
    "# There is a runtime warning but just be patient\n",
    "\n",
    "for ind, lambda_ in enumerate(lambdas):\n",
    "    \n",
    "    losses, ws = reg_logistic_regression(y_train_sample, X_train_sample, initial_w, lamb = lambda_, methods ='gd', gamma = 0.0001, max_iters=5000)\n",
    "    loss_tr.append(losses[-1])\n",
    "    best_w = ws[-1]\n",
    "    \n",
    "    pred_tr.append(pred_accuracy(predict_labels_logistic(best_w, X_train_sample),y_train_sample))\n",
    "    \n",
    "    test_losses = compute_loss(y_test_sample, X_test_sample, best_w, lam = lambda_, method = 'reg_logistic') # retrieve losses using test set with ws\n",
    "    loss_ts.append(test_losses)\n",
    "    pred_ts.append(pred_accuracy(predict_labels_logistic(best_w, X_test_sample),y_test_sample))\n",
    "\n",
    "    \n",
    "plt.style.use('seaborn')\n",
    "plt.semilogx(lambdas,loss_tr, c='blue')\n",
    "plt.semilogx(lambdas,loss_ts, c='red')\n",
    "plt.legend(['training set', 'testing set'], loc='upper left')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "plt.semilogx(lambdas,pred_tr, c='blue')\n",
    "plt.semilogx(lambdas,pred_ts, c='red')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['training set', 'testing set'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lamb = 0.1\n",
    "# losses, ws = reg_logistic_regression(y_train, X_train, \n",
    "#                          initial_w, lamb, methods = 'gd', \n",
    "#                          gamma = 0.01, max_iters= 6000)\n",
    "\n",
    "# test_losses = list(map(lambda x: compute_loss(y_test, X_test, x, lam = lamb, method = 'reg_logistic'), ws)) # retrieve losses using test set with ws\n",
    "# plt.style.use('seaborn')\n",
    "# plt.plot(losses, label='Training set loss', c='blue')\n",
    "# plt.plot(test_losses, label='Test set loss', c='red')\n",
    "# plt.xlabel('Iteration')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Regularized Logistic Regression: Cost Function Loss Over Iterations of Gradient Descent')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # Make plot with label prediction accuracy\n",
    "\n",
    "# pred_ytrain = list(map(lambda x: predict_labels(x, X_train), ws)) # Training prediction\n",
    "# pred_accuracytrain = list(map(lambda x: pred_accuracy(x, y_train), pred_ytrain))\n",
    "# pred_ytest = list(map(lambda x: predict_labels(x, X_test), ws)) # Test prediction\n",
    "# pred_accuracytest = list(map(lambda x: pred_accuracy(x, y_test), pred_ytest))\n",
    "\n",
    "\n",
    "# plt.plot(pred_accuracytrain, label='Training set prediction accuracy', c='blue')\n",
    "# plt.plot(pred_accuracytest, label='Test set prediction accuracy', c='red')\n",
    "# plt.legend()\n",
    "# plt.xlabel('Iteration')\n",
    "# plt.ylabel('Prediction Accuracy')\n",
    "# plt.title('Regularized Logistic Regression Prediction Accuracy Over Iterations of Gradient Descent')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the polynomial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 12\n",
    "X_test_poly = build_poly(data_test,degree)\n",
    "X_train_poly = build_poly(data,degree)\n",
    "w = least_squares(labels, X_train_poly)\n",
    "rmse_tr = (np.sqrt(2 * compute_loss(labels, X_train_poly, w)))\n",
    "pred_tr = pred_accuracy(predict_labels(w,X_train_poly),labels)\n",
    "\n",
    "test_prediction = predict_labels(w, X_test_poly)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"prediction.csv\"\n",
    "ids = ids_test\n",
    "y_pred = test_prediction\n",
    "create_csv_submission(ids, y_pred, name)\n",
    "\n",
    "# this yielded like 0.62 on kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = np.ones(tx.shape[1])\n",
    "y[y == -1] = 0\n",
    "losses, ws = logistic_regression(y, tx, initial_w, method = 'sgd', max_iters = 6000) # fit model, retrieve parameters ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tx_t.dot(ws[-1])\n",
    "pred[np.where(pred <= 0.5)] = -1\n",
    "pred[np.where(pred > 0.5)] = 1\n",
    "\n",
    "name = \"prediction.csv\"\n",
    "create_csv_submission(t_ids, pred, name)\n",
    "\n",
    "# this yields 0.73 on kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = np.ones(tx.shape[1])\n",
    "y[y == -1] = 0\n",
    "losses, ws = reg_logistic_regression(y, tx, initial_w, lamb = 0.1, methods = 'sgd', max_iters = 20000, gamma = 0.0001)\n",
    "\n",
    "pred = tx_t.dot(ws[-1])\n",
    "pred[np.where(pred <= 0.5)] = -1\n",
    "pred[np.where(pred > 0.5)] = 1\n",
    "\n",
    "name = \"prediction_2.csv\"\n",
    "create_csv_submission(t_ids, pred, name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
