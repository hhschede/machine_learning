{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the imports\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the important functions\n",
    "from implementations import *\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload data\n",
    "(labels, data, ids) = load_csv_data(\"C:/Users/remy/Documents/data/train.csv\")  # load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000,)\n",
      "(250000, 30)\n",
      "(250000,)\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape)\n",
    "print(data.shape)\n",
    "print(ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set values of -999 to NaN. \n",
    "# Then calculate the means of the features. \n",
    "# Replace NaN values with new values.\n",
    "\n",
    "data_process = np.array(data[:1000,:])\n",
    "labels_select = np.array(labels[:1000])\n",
    "lab = []\n",
    "for entry in labels_select:\n",
    "    if int(entry) == 1:\n",
    "        lab.append(1)\n",
    "    else:\n",
    "        lab.append(0)\n",
    "lab = np.array(lab)\n",
    "data_process[data_process == -999] = np.nan\n",
    "\n",
    "# print(data_process.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out really shitty features\n",
    "# retrieve percentage for each feature \n",
    "# - how many nan's are there?\n",
    "\n",
    "nan_count = []\n",
    "for c in data_process.T:\n",
    "    count = 0\n",
    "    for e in c:\n",
    "        if np.isnan(e):\n",
    "            count += 1\n",
    "    pcent = count / data_process.shape[0]\n",
    "    nan_count.append(pcent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out features which have nan values of 50%\n",
    "\n",
    "data_set_filtered = []\n",
    "for idx, entry in enumerate(nan_count):\n",
    "    if entry < 0.6:\n",
    "        #append the column of the original dataset that is good\n",
    "        data_set_filtered.append(data_process.T[idx]) \n",
    "#save that shit as an np array\n",
    "data_set_filtered = np.array(data_set_filtered).T #save that shit as an np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out samples that have more than half of their features as nan (crappy samples)\n",
    "\n",
    "nan_count_2 = []\n",
    "data_set_filtered_2 = [] # dataset filtered for columns and samples\n",
    "y = [] # array that gets rid of entries that are no longer corresponding in the dataframe\n",
    "for sample in data_set_filtered:\n",
    "    count = 0\n",
    "    for col in sample:\n",
    "        if np.isnan(col):\n",
    "            count += 1\n",
    "    pcent = count / data_set_filtered.shape[1]\n",
    "    nan_count_2.append(pcent)\n",
    "\n",
    "for idx, entry in enumerate(nan_count_2):\n",
    "    if entry < 0.15:\n",
    "        y.append(lab[idx])\n",
    "        data_set_filtered_2.append(data_set_filtered[idx])\n",
    "data_set_filtered_2 = np.array(data_set_filtered_2) # turn dat shit into an array\n",
    "y = np.array(y) # also this one gotta be an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original dimensions of the training data set was 1000 samples and 30 columns. After feature and sample filtering, there are 909 samples and 23 columns\n"
     ]
    }
   ],
   "source": [
    "# print new dimensions of the dataframe after filtering\n",
    "\n",
    "print('The original dimensions of the training data set was {0} samples'\n",
    "      ' and {1} columns. After feature and sample filtering, there are'\n",
    "      ' {2} samples and {3} columns'.format(data_process.shape[0],\n",
    "                                            data_process.shape[1],\n",
    "                                            data_set_filtered_2.shape[0],\n",
    "                                            data_set_filtered_2.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable reassigned\n",
    "data_nan = data_set_filtered_2.copy() \n",
    "# create list with average values of columns, excluding nans\n",
    "column_means = [] \n",
    "for column in data_nan.T:\n",
    "    column_means.append(np.nanmean(column))\n",
    "    \n",
    "\n",
    "# variable containing locations of nan in data frame\n",
    "inds = np.where(np.isnan(data_nan)) \n",
    "# reassign locations of nan to the column means\n",
    "data_nan[inds] = np.take(column_means, inds[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize and normalize the features\n",
    "column_variance = []\n",
    "for idx, column in enumerate(data_nan.T):\n",
    "    mean = np.mean(column)\n",
    "    variance = np.var(column)\n",
    "    for entry, value in enumerate(column):\n",
    "        data_nan[entry, idx] = (value - mean)/variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPRESS DATA BY PCA. Note that this is an unsupervised method and might not be a good alternative\n",
    "\n",
    "# pca_ = pca(percent_rep=0.9)\n",
    "# pca_.fit(data_nan)\n",
    "# pca_data = pca_.transform(data_nan)\n",
    "#\n",
    "# pca_data_A = []\n",
    "# pca_data_B = []\n",
    "# for idx, entry in enumerate(labels_select):\n",
    "#     if entry == 1:\n",
    "#         pca_data_A.append(pca_data[idx])\n",
    "#     else:\n",
    "#         pca_data_B.append(pca_data[idx])\n",
    "# pca_data_A = np.array(pca_data_A)\n",
    "# pca_data_B = np.array(pca_data_B)\n",
    "#\n",
    "# fig = plt.figure()\n",
    "# scattered = plt.axes(projection = '3d')\n",
    "# scattered.scatter3D(pca_data_A[:,0], pca_data_A[:,1], pca_data_A[:,2], c='blue')\n",
    "# scattered.scatter3D(pca_data_B[:,0], pca_data_B[:,1], pca_data_B[:,2], c='red')\n",
    "#\n",
    "# plt.show()\n",
    "# pca_int = logreg.add_int(pca_data)\n",
    "# prediction = logreg.predict_class(pca_int)\n",
    "# print(prediction)\n",
    "\n",
    "# add some non-linear variants of each of the features that are included in the data set\n",
    "# do this by constructing a new array, which will then be concatenated with the old one\n",
    "# note that the addition of the squared features increases accuracy by a few percentage\n",
    "# but there is a smaller, but clear, difference with the cubed features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate_me = []\n",
    "\n",
    "# for col in data_nan.T:\n",
    "#     col_squared = [entry**2 for entry in col]\n",
    "#     col_cubed = [entry ** 3 for entry in col]\n",
    "#     concatenate_me.append(col_squared)\n",
    "#     concatenate_me.append(col_cubed)\n",
    "\n",
    "# concatenate_me = np.array(concatenate_me).T\n",
    "# data_concatenated = np.concatenate((data_nan, concatenate_me), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(909, 23)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_nan.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\remy\\Documents\\machine_learning\\project_1\\implementations.py:155: RuntimeWarning: divide by zero encountered in log\n",
      "  return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n",
      "C:\\Users\\remy\\Documents\\machine_learning\\project_1\\implementations.py:155: RuntimeWarning: invalid value encountered in multiply\n",
      "  return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 | accuracy : 0.43471479500891264, loss : nan\n",
      "iteration: 500 | accuracy : 0.5934714795008913, loss : 1.0892098101847942\n",
      "iteration: 1000 | accuracy : 0.6281194295900179, loss : 0.7670669352752669\n",
      "iteration: 1500 | accuracy : 0.670120320855615, loss : nan\n",
      "iteration: 2000 | accuracy : 0.6720142602495544, loss : 0.6401741389912253\n",
      "iteration: 2500 | accuracy : 0.6915106951871658, loss : nan\n",
      "iteration: 3000 | accuracy : 0.6946301247771836, loss : 0.5842166790386295\n",
      "iteration: 3500 | accuracy : 0.7004233511586453, loss : 0.5772469895126368\n",
      "iteration: 4000 | accuracy : 0.7027629233511586, loss : 0.5750838187532412\n",
      "iteration: 4500 | accuracy : 0.6878342245989305, loss : inf\n",
      "iteration: 5000 | accuracy : 0.7030971479500892, loss : nan\n",
      "iteration: 5500 | accuracy : 0.7039884135472371, loss : nan\n",
      "iteration: 6000 | accuracy : 0.7090017825311943, loss : 0.567219663628794\n",
      "iteration: 6500 | accuracy : 0.7092245989304813, loss : 0.5657530935181705\n",
      "iteration: 7000 | accuracy : 0.7074420677361853, loss : 0.6049953934603916\n",
      "iteration: 7500 | accuracy : 0.7129010695187166, loss : 0.56839195884392\n",
      "iteration: 8000 | accuracy : 0.7124554367201426, loss : 0.5703110940033703\n",
      "iteration: 8500 | accuracy : 0.7108957219251337, loss : 0.5854748298089998\n",
      "iteration: 9000 | accuracy : 0.7038770053475936, loss : 0.5770764892607215\n",
      "iteration: 9500 | accuracy : 0.7102272727272727, loss : 0.5600892613990436\n",
      "iteration: 0 | accuracy : 0.43404634581105167, loss : nan\n",
      "iteration: 500 | accuracy : 0.5907976827094474, loss : 1.0778896692943145\n",
      "iteration: 1000 | accuracy : 0.635806595365419, loss : 0.7504531799399715\n",
      "iteration: 1500 | accuracy : 0.6570855614973262, loss : 0.6476924342671416\n",
      "iteration: 2000 | accuracy : 0.6746880570409982, loss : 0.6053580077363161\n",
      "iteration: 2500 | accuracy : 0.6909536541889483, loss : 0.5854816946160465\n",
      "iteration: 3000 | accuracy : 0.6974153297682709, loss : 0.5752392900206614\n",
      "iteration: 3500 | accuracy : 0.7010918003565062, loss : 0.5695180617361658\n",
      "iteration: 4000 | accuracy : 0.7018716577540107, loss : 0.5660594216125283\n",
      "iteration: 4500 | accuracy : 0.7049910873440285, loss : 0.563798930962855\n",
      "iteration: 5000 | accuracy : 0.7054367201426025, loss : 0.562209345722064\n",
      "iteration: 5500 | accuracy : 0.70599376114082, loss : 0.5610178638287202\n",
      "iteration: 6000 | accuracy : 0.7067736185383244, loss : 0.5600771780981957\n",
      "iteration: 6500 | accuracy : 0.7072192513368984, loss : 0.5593040843953465\n",
      "iteration: 7000 | accuracy : 0.7071078431372549, loss : 0.5586492608992506\n",
      "iteration: 7500 | accuracy : 0.7090017825311943, loss : 0.5580819574166184\n",
      "iteration: 8000 | accuracy : 0.7103386809269162, loss : 0.5575820163599906\n",
      "iteration: 8500 | accuracy : 0.7123440285204992, loss : 0.5571355865431183\n",
      "iteration: 9000 | accuracy : 0.7131238859180036, loss : 0.5567327419946444\n",
      "iteration: 9500 | accuracy : 0.7122326203208557, loss : 0.5563661093596972\n"
     ]
    }
   ],
   "source": [
    "# perform the linear regression\n",
    "# i just noticed that the prediction accuracy also depends quite a bit on the initialized w.\n",
    "# for example if you initialize them all to ones instead of zeros, accuracy increases. overfitting?\n",
    "\n",
    "\n",
    "\n",
    "logreg_SGD = LogisticRegression(writing=True)\n",
    "accuracy_SGD, loss_SGD = logreg_SGD.fit(data_nan, y,\"sgd\")\n",
    "\n",
    "logreg_GD = LogisticRegression(writing=True)\n",
    "accuracy_GD, loss_GD = logreg.fit(data_nan, y,\"gd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1cfd8657dd8>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracy_GD)\n",
    "plt.plot(accuracy_SGD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT DATA\n",
    "\n",
    "#(X_train, y_train, X_test, y_test) = test_train(data, labels, test_ratio=0.3)  # split into train and test set\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "\n",
    "# # CALCULATE FISHER SCORE VARIANT\n",
    "#\n",
    "# scores = []\n",
    "# means_A = []\n",
    "# var_A = []\n",
    "# means_B = []\n",
    "# var_B = []\n",
    "# class_A = np.array(data_nan[np.argwhere(y == 1)])# separate out classes\n",
    "# class_A = class_A[:,0,:]\n",
    "# class_B = np.array(data_nan[np.argwhere(y == 0)])\n",
    "# class_B = class_B[:,0,:]\n",
    "#\n",
    "# for c in class_A.T:\n",
    "#     means_A.append(np.mean(c))\n",
    "#     var_A.append(np.var(c))\n",
    "# for c in class_B.T:\n",
    "#     means_B.append(np.mean(c))\n",
    "#     var_B.append(np.mean(c))\n",
    "# for x in range(len(means_A)):\n",
    "#     scores.append(means_A[x] - means_B[x]) # score function\n",
    "# print(np.array(scores))\n",
    "#\n",
    "#\n",
    "# # fig = plt.figure()\n",
    "# # scattered = plt.axes(projection = '3d')\n",
    "# # scattered.scatter3D(class_A[:,12], class_A[:,28], class_A[:,4], c='blue')\n",
    "# # scattered.scatter3D(class_B[:,12], class_B[:,28], class_B[:,4], c='red')\n",
    "# fig = plt.figure()\n",
    "# plt.scatter(class_B[:,12], class_B[:,10], c='blue', alpha=0.2)\n",
    "# plt.scatter(class_A[:,12], class_A[:,10], c='red', alpha=0.2)\n",
    "#\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
